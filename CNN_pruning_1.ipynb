{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-eC-sb34T9w"
      },
      "source": [
        "## Accelerate Inference: Neural Network Pruning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L47XBZWm4T9x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c6856e4-1d45-4e3e-a7ea-507acca449d9"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import datasets, layers, models, regularizers\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import clone_model\n",
        "\n",
        "\n",
        "print(tf.version.VERSION)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.14.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHTv5v-Wntli",
        "outputId": "50d32a12-0944-43b7-a696-64ee70756379"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1FQTVeAuNiU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a6e406f-7b0b-491b-ff69-fe09ac8b1358"
      },
      "source": [
        "# untar\n",
        "!tar -xvzf '/content/drive/My Drive/dataset.tar.gz'\n",
        "# load train\n",
        "train_images = pickle.load(open('train_images.pkl', 'rb'))\n",
        "train_labels = pickle.load(open('train_labels.pkl', 'rb'))\n",
        "# load val\n",
        "val_images = pickle.load(open('val_images.pkl', 'rb'))\n",
        "val_labels = pickle.load(open('val_labels.pkl', 'rb'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_images.pkl\n",
            "train_labels.pkl\n",
            "val_images.pkl\n",
            "val_labels.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KE9JuZDG4T94"
      },
      "source": [
        "# Define the neural network architecture (don't change this)\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding='same', kernel_regularizer=regularizers.l2(1e-5), input_shape=(25,25,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(1e-5)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(64, (3, 3), padding='same', kernel_regularizer=regularizers.l2(1e-5)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(1e-5)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(5))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTzcSoYl4T97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4be0f1c-2754-41c5-f3a4-93e88d7f7529"
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 25, 25, 32)        896       \n",
            "                                                                 \n",
            " activation (Activation)     (None, 25, 25, 32)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 23, 23, 32)        9248      \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 23, 23, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 11, 11, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 11, 11, 32)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 11, 11, 64)        18496     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 11, 11, 64)        0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 9, 9, 64)          36928     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 9, 9, 64)          0         \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 4, 4, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 4, 4, 64)          0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               524800    \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 512)               0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 2565      \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 5)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 592933 (2.26 MB)\n",
            "Trainable params: 592933 (2.26 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9Nk_MAPqZPt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b8919df-bfdb-4a5d-b349-a49b142ef6a3"
      },
      "source": [
        "# you can use the default hyper-parameters for training,\n",
        "# val accuracy ~72% after 50 epochs\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001, weight_decay=1e-6),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_images, train_labels, batch_size=32, epochs=80,\n",
        "                    validation_data=(val_images, val_labels)) # train for 50 epochs, with batch size 32"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "703/703 [==============================] - 9s 5ms/step - loss: 1.5338 - accuracy: 0.3002 - val_loss: 1.4043 - val_accuracy: 0.4059\n",
            "Epoch 2/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.3683 - accuracy: 0.4099 - val_loss: 1.2774 - val_accuracy: 0.4630\n",
            "Epoch 3/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.2960 - accuracy: 0.4544 - val_loss: 1.2260 - val_accuracy: 0.4855\n",
            "Epoch 4/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.2441 - accuracy: 0.4800 - val_loss: 1.2186 - val_accuracy: 0.4844\n",
            "Epoch 5/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.2118 - accuracy: 0.5002 - val_loss: 1.1768 - val_accuracy: 0.5042\n",
            "Epoch 6/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.1802 - accuracy: 0.5176 - val_loss: 1.1237 - val_accuracy: 0.5398\n",
            "Epoch 7/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.1514 - accuracy: 0.5293 - val_loss: 1.1048 - val_accuracy: 0.5414\n",
            "Epoch 8/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.1213 - accuracy: 0.5476 - val_loss: 1.0829 - val_accuracy: 0.5651\n",
            "Epoch 9/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.0963 - accuracy: 0.5580 - val_loss: 1.0439 - val_accuracy: 0.5758\n",
            "Epoch 10/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.0771 - accuracy: 0.5699 - val_loss: 1.0290 - val_accuracy: 0.5850\n",
            "Epoch 11/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.0567 - accuracy: 0.5782 - val_loss: 1.0147 - val_accuracy: 0.5814\n",
            "Epoch 12/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.0389 - accuracy: 0.5888 - val_loss: 1.0002 - val_accuracy: 0.5913\n",
            "Epoch 13/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.0191 - accuracy: 0.5972 - val_loss: 0.9910 - val_accuracy: 0.5988\n",
            "Epoch 14/80\n",
            "703/703 [==============================] - 4s 5ms/step - loss: 1.0013 - accuracy: 0.6045 - val_loss: 0.9591 - val_accuracy: 0.6162\n",
            "Epoch 15/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9881 - accuracy: 0.6117 - val_loss: 0.9594 - val_accuracy: 0.6202\n",
            "Epoch 16/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9679 - accuracy: 0.6211 - val_loss: 0.9452 - val_accuracy: 0.6293\n",
            "Epoch 17/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9596 - accuracy: 0.6249 - val_loss: 0.9607 - val_accuracy: 0.6194\n",
            "Epoch 18/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9424 - accuracy: 0.6328 - val_loss: 0.9412 - val_accuracy: 0.6325\n",
            "Epoch 19/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9286 - accuracy: 0.6371 - val_loss: 0.9146 - val_accuracy: 0.6356\n",
            "Epoch 20/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9119 - accuracy: 0.6469 - val_loss: 0.9020 - val_accuracy: 0.6440\n",
            "Epoch 21/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.8944 - accuracy: 0.6515 - val_loss: 0.8955 - val_accuracy: 0.6463\n",
            "Epoch 22/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.8832 - accuracy: 0.6595 - val_loss: 0.8784 - val_accuracy: 0.6547\n",
            "Epoch 23/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.8714 - accuracy: 0.6642 - val_loss: 0.8452 - val_accuracy: 0.6709\n",
            "Epoch 24/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.8614 - accuracy: 0.6718 - val_loss: 0.8670 - val_accuracy: 0.6661\n",
            "Epoch 25/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.8424 - accuracy: 0.6800 - val_loss: 0.8647 - val_accuracy: 0.6566\n",
            "Epoch 26/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.8340 - accuracy: 0.6803 - val_loss: 0.8763 - val_accuracy: 0.6539\n",
            "Epoch 27/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.8199 - accuracy: 0.6851 - val_loss: 0.8164 - val_accuracy: 0.6859\n",
            "Epoch 28/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.8087 - accuracy: 0.6903 - val_loss: 0.8191 - val_accuracy: 0.6752\n",
            "Epoch 29/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.8001 - accuracy: 0.6948 - val_loss: 0.8397 - val_accuracy: 0.6776\n",
            "Epoch 30/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.7894 - accuracy: 0.7004 - val_loss: 0.8090 - val_accuracy: 0.6891\n",
            "Epoch 31/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.7792 - accuracy: 0.7046 - val_loss: 0.7976 - val_accuracy: 0.6935\n",
            "Epoch 32/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.7726 - accuracy: 0.7047 - val_loss: 0.7971 - val_accuracy: 0.6931\n",
            "Epoch 33/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.7600 - accuracy: 0.7107 - val_loss: 0.7948 - val_accuracy: 0.6950\n",
            "Epoch 34/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.7519 - accuracy: 0.7156 - val_loss: 0.7889 - val_accuracy: 0.6939\n",
            "Epoch 35/80\n",
            "703/703 [==============================] - 4s 5ms/step - loss: 0.7385 - accuracy: 0.7192 - val_loss: 0.7848 - val_accuracy: 0.6939\n",
            "Epoch 36/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.7308 - accuracy: 0.7215 - val_loss: 0.7953 - val_accuracy: 0.6970\n",
            "Epoch 37/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.7163 - accuracy: 0.7279 - val_loss: 0.7775 - val_accuracy: 0.6982\n",
            "Epoch 38/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.7140 - accuracy: 0.7289 - val_loss: 0.8051 - val_accuracy: 0.6919\n",
            "Epoch 39/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.7099 - accuracy: 0.7332 - val_loss: 0.7742 - val_accuracy: 0.7046\n",
            "Epoch 40/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6939 - accuracy: 0.7344 - val_loss: 0.8006 - val_accuracy: 0.7050\n",
            "Epoch 41/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6845 - accuracy: 0.7414 - val_loss: 0.7941 - val_accuracy: 0.6982\n",
            "Epoch 42/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6814 - accuracy: 0.7445 - val_loss: 0.7641 - val_accuracy: 0.7133\n",
            "Epoch 43/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6781 - accuracy: 0.7448 - val_loss: 0.7411 - val_accuracy: 0.7160\n",
            "Epoch 44/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6677 - accuracy: 0.7509 - val_loss: 0.7454 - val_accuracy: 0.7141\n",
            "Epoch 45/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6567 - accuracy: 0.7514 - val_loss: 0.7667 - val_accuracy: 0.7105\n",
            "Epoch 46/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6406 - accuracy: 0.7570 - val_loss: 0.7303 - val_accuracy: 0.7200\n",
            "Epoch 47/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6396 - accuracy: 0.7585 - val_loss: 0.7320 - val_accuracy: 0.7236\n",
            "Epoch 48/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6410 - accuracy: 0.7595 - val_loss: 0.7364 - val_accuracy: 0.7164\n",
            "Epoch 49/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6280 - accuracy: 0.7634 - val_loss: 0.7606 - val_accuracy: 0.7089\n",
            "Epoch 50/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6158 - accuracy: 0.7687 - val_loss: 0.7350 - val_accuracy: 0.7220\n",
            "Epoch 51/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6092 - accuracy: 0.7702 - val_loss: 0.7364 - val_accuracy: 0.7168\n",
            "Epoch 52/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6050 - accuracy: 0.7718 - val_loss: 0.7328 - val_accuracy: 0.7208\n",
            "Epoch 53/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.5947 - accuracy: 0.7761 - val_loss: 0.7264 - val_accuracy: 0.7307\n",
            "Epoch 54/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.5895 - accuracy: 0.7794 - val_loss: 0.7484 - val_accuracy: 0.7149\n",
            "Epoch 55/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.5793 - accuracy: 0.7833 - val_loss: 0.7595 - val_accuracy: 0.7141\n",
            "Epoch 56/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.5740 - accuracy: 0.7865 - val_loss: 0.7334 - val_accuracy: 0.7224\n",
            "Epoch 57/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.5665 - accuracy: 0.7911 - val_loss: 0.7299 - val_accuracy: 0.7176\n",
            "Epoch 58/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.5623 - accuracy: 0.7896 - val_loss: 0.7310 - val_accuracy: 0.7283\n",
            "Epoch 59/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.5544 - accuracy: 0.7888 - val_loss: 0.7160 - val_accuracy: 0.7291\n",
            "Epoch 60/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.5502 - accuracy: 0.7965 - val_loss: 0.7083 - val_accuracy: 0.7343\n",
            "Epoch 61/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.5429 - accuracy: 0.7976 - val_loss: 0.7301 - val_accuracy: 0.7251\n",
            "Epoch 62/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.5337 - accuracy: 0.7998 - val_loss: 0.7091 - val_accuracy: 0.7331\n",
            "Epoch 63/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.5298 - accuracy: 0.8036 - val_loss: 0.7356 - val_accuracy: 0.7275\n",
            "Epoch 64/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.5201 - accuracy: 0.8053 - val_loss: 0.7495 - val_accuracy: 0.7200\n",
            "Epoch 65/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.5158 - accuracy: 0.8065 - val_loss: 0.7204 - val_accuracy: 0.7394\n",
            "Epoch 66/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.5070 - accuracy: 0.8113 - val_loss: 0.7554 - val_accuracy: 0.7307\n",
            "Epoch 67/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.5011 - accuracy: 0.8130 - val_loss: 0.7269 - val_accuracy: 0.7315\n",
            "Epoch 68/80\n",
            "703/703 [==============================] - 4s 5ms/step - loss: 0.4997 - accuracy: 0.8154 - val_loss: 0.7583 - val_accuracy: 0.7259\n",
            "Epoch 69/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.4910 - accuracy: 0.8166 - val_loss: 0.7261 - val_accuracy: 0.7343\n",
            "Epoch 70/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.4859 - accuracy: 0.8209 - val_loss: 0.7265 - val_accuracy: 0.7299\n",
            "Epoch 71/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.4865 - accuracy: 0.8195 - val_loss: 0.7129 - val_accuracy: 0.7378\n",
            "Epoch 72/80\n",
            "703/703 [==============================] - 4s 5ms/step - loss: 0.4725 - accuracy: 0.8283 - val_loss: 0.7382 - val_accuracy: 0.7259\n",
            "Epoch 73/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.4638 - accuracy: 0.8281 - val_loss: 0.7129 - val_accuracy: 0.7406\n",
            "Epoch 74/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.4665 - accuracy: 0.8288 - val_loss: 0.7184 - val_accuracy: 0.7362\n",
            "Epoch 75/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.4586 - accuracy: 0.8320 - val_loss: 0.7290 - val_accuracy: 0.7386\n",
            "Epoch 76/80\n",
            "703/703 [==============================] - 4s 5ms/step - loss: 0.4521 - accuracy: 0.8323 - val_loss: 0.7166 - val_accuracy: 0.7366\n",
            "Epoch 77/80\n",
            "703/703 [==============================] - 4s 5ms/step - loss: 0.4520 - accuracy: 0.8319 - val_loss: 0.7381 - val_accuracy: 0.7299\n",
            "Epoch 78/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.4416 - accuracy: 0.8354 - val_loss: 0.7157 - val_accuracy: 0.7434\n",
            "Epoch 79/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.4442 - accuracy: 0.8350 - val_loss: 0.7146 - val_accuracy: 0.7386\n",
            "Epoch 80/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.4342 - accuracy: 0.8381 - val_loss: 0.7312 - val_accuracy: 0.7358\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOhpP7M24T9_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12858bb5-3521-47c7-f4cb-88a91d572110"
      },
      "source": [
        "results = model.evaluate(val_images, val_labels, batch_size=128)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 0s 9ms/step - loss: 0.7312 - accuracy: 0.7358\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Magnitude-based pruning - Percentile-based global threshold determination"
      ],
      "metadata": {
        "id": "3aaIZR9ZAMVh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prune_and_retrain(model, train_images, train_labels, val_images, val_labels,\n",
        "                      pruning_rate=0.1, retrain_epochs=10, batch_size=128):\n",
        "    pruned_model = clone_model(model)\n",
        "    pruned_model.set_weights(model.get_weights())  # Copy weights from the original model\n",
        "\n",
        "    weights = model.get_weights()\n",
        "    # Step 1: Prune the network\n",
        "    flat_weights = np.concatenate([w.flatten() for w in weights if w.ndim > 1])\n",
        "    threshold = np.percentile(np.abs(flat_weights), pruning_rate * 100)\n",
        "\n",
        "    new_weights = []\n",
        "    for w in weights:\n",
        "        if w.ndim > 1:  # Applies to weights in Conv and Dense layers\n",
        "            new_w = np.where(np.abs(w) < threshold, 0, w)\n",
        "        else:  # Bias and other parameters are typically not pruned\n",
        "            new_w = w\n",
        "        new_weights.append(new_w)\n",
        "    pruned_model.set_weights(new_weights)\n",
        "\n",
        "    # Step 2: Retrain the network\n",
        "    pruned_model.compile(optimizer='adam',\n",
        "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # use a lower learning rate for retraining\n",
        "    old_lr = tf.keras.backend.get_value(pruned_model.optimizer.lr)\n",
        "    new_lr = old_lr * 0.1\n",
        "    tf.keras.backend.set_value(pruned_model.optimizer.lr, new_lr)\n",
        "\n",
        "    history = pruned_model.fit(train_images, train_labels,\n",
        "                        batch_size=batch_size,\n",
        "                        epochs=retrain_epochs,\n",
        "                        validation_data=(val_images, val_labels))\n",
        "\n",
        "    # Restore the original learning rate if desired\n",
        "    # tf.keras.backend.set_value(model.optimizer.lr, old_lr)\n",
        "\n",
        "    return history, new_weights, pruned_model\n",
        "\n",
        "history, pruned_weights, pruned_model = prune_and_retrain(model, train_images, train_labels, val_images, val_labels,\n",
        "                            pruning_rate=0.95, retrain_epochs=15, batch_size=32)\n",
        "\n",
        "# Evaluate the pruned model\n",
        "val_loss, val_accuracy = pruned_model.evaluate(val_images, val_labels, batch_size=128)\n",
        "print(f\"Validation Accuracy: {val_accuracy}\")\n",
        "\n",
        "# Calculate the total number of weights\n",
        "total_weights = np.sum([np.prod(w.shape) for w in pruned_weights])\n",
        "\n",
        "# Calculate the number of zero weights (sparsity)\n",
        "num_zero_weights = np.sum([np.count_nonzero(w == 0) for w in pruned_weights])\n",
        "sparsity = num_zero_weights / total_weights\n",
        "print(f\"Sparsity: {sparsity}\")\n",
        "\n",
        "# Calculate the score based on the provided formula\n",
        "if val_accuracy > 0.6 and sparsity > 0:\n",
        "    score = (val_accuracy + sparsity) / 2\n",
        "else:\n",
        "    score = 0\n",
        "\n",
        "print(f\"Model Score: {score}\")"
      ],
      "metadata": {
        "id": "pkZ_sV2A3Eno",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59fd5629-9fe0-41a5-e18e-2e821efd054b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "703/703 [==============================] - 5s 5ms/step - loss: 1.0746 - accuracy: 0.5705 - val_loss: 0.8689 - val_accuracy: 0.6574\n",
            "Epoch 2/15\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.8696 - accuracy: 0.6635 - val_loss: 0.8106 - val_accuracy: 0.6943\n",
            "Epoch 3/15\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.8109 - accuracy: 0.6872 - val_loss: 0.7770 - val_accuracy: 0.7002\n",
            "Epoch 4/15\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.7794 - accuracy: 0.7025 - val_loss: 0.7807 - val_accuracy: 0.6994\n",
            "Epoch 5/15\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 0.7491 - accuracy: 0.7115 - val_loss: 0.7662 - val_accuracy: 0.7014\n",
            "Epoch 6/15\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.7292 - accuracy: 0.7240 - val_loss: 0.7610 - val_accuracy: 0.7125\n",
            "Epoch 7/15\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.7100 - accuracy: 0.7295 - val_loss: 0.7344 - val_accuracy: 0.7180\n",
            "Epoch 8/15\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 0.6944 - accuracy: 0.7389 - val_loss: 0.7300 - val_accuracy: 0.7240\n",
            "Epoch 9/15\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 0.6766 - accuracy: 0.7390 - val_loss: 0.7439 - val_accuracy: 0.7137\n",
            "Epoch 10/15\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6657 - accuracy: 0.7477 - val_loss: 0.7278 - val_accuracy: 0.7255\n",
            "Epoch 11/15\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6482 - accuracy: 0.7567 - val_loss: 0.7183 - val_accuracy: 0.7279\n",
            "Epoch 12/15\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6321 - accuracy: 0.7617 - val_loss: 0.7354 - val_accuracy: 0.7208\n",
            "Epoch 13/15\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6241 - accuracy: 0.7645 - val_loss: 0.7164 - val_accuracy: 0.7390\n",
            "Epoch 14/15\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6066 - accuracy: 0.7724 - val_loss: 0.7112 - val_accuracy: 0.7343\n",
            "Epoch 15/15\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6023 - accuracy: 0.7762 - val_loss: 0.7051 - val_accuracy: 0.7434\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.7051 - accuracy: 0.7434\n",
            "Validation Accuracy: 0.7433663606643677\n",
            "Sparsity: 0.9488626876898402\n",
            "Model Score: 0.846114524177104\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# you need to save the model's weights, naming it 'my_model_weights.h5'\n",
        "pruned_model.save_weights(\"my_model_weights_1.h5\")\n",
        "\n",
        "# running this cell will immediately download a file called 'my_model_weights.h5'\n",
        "from google.colab import files\n",
        "files.download(\"my_model_weights_1.h5\")"
      ],
      "metadata": {
        "id": "VH87kCRGS3C5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5fb304b3-28d1-4be2-e1c2-80dfcf428135"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_38713f32-760a-4cac-b03b-f359595ddd14\", \"my_model_weights_1.h5\", 2407040)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Magnitude-based pruning - Standard deviation-based threshold determination"
      ],
      "metadata": {
        "id": "7QkzsY8lL_I7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "def prune_and_retrain(model, train_images, train_labels, val_images, val_labels, quality_parameter=0.5, retrain_epochs=10, batch_size=128):\n",
        "    pruned_model = clone_model(model)\n",
        "    pruned_model.set_weights(model.get_weights())  # Copy weights from the original model\n",
        "\n",
        "    # Get the weights of the model\n",
        "    weights = model.get_weights()\n",
        "\n",
        "    # Step 1: Prune the network using a layer-specific standard deviation-based threshold\n",
        "    new_weights = []\n",
        "    for w in weights:\n",
        "        if w.ndim > 1:  # Applies to weights in Conv and Dense layers\n",
        "            # Calculate the threshold as a quality parameter times the standard deviation\n",
        "            threshold = quality_parameter * np.std(w)\n",
        "            new_w = np.where(np.abs(w) < threshold, 0, w)\n",
        "        else:  # Bias and other parameters are typically not pruned\n",
        "            new_w = w\n",
        "        new_weights.append(new_w)\n",
        "\n",
        "    pruned_model.set_weights(new_weights)\n",
        "\n",
        "    # Step 2: Retrain the network\n",
        "    pruned_model.compile(optimizer='adam',\n",
        "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # use a lower learning rate for retraining\n",
        "    old_lr = tf.keras.backend.get_value(pruned_model.optimizer.lr)\n",
        "    new_lr = old_lr * 0.1\n",
        "    tf.keras.backend.set_value(pruned_model.optimizer.lr, new_lr)\n",
        "\n",
        "    history = pruned_model.fit(train_images, train_labels,\n",
        "                        batch_size=batch_size,\n",
        "                        epochs=retrain_epochs,\n",
        "                        validation_data=(val_images, val_labels))\n",
        "\n",
        "    # Restore the original learning rate if desired\n",
        "    # tf.keras.backend.set_value(pruned_model.optimizer.lr, old_lr)\n",
        "\n",
        "    return history, new_weights, pruned_model\n",
        "\n",
        "history, pruned_weights, pruned_model = prune_and_retrain(model, train_images, train_labels, val_images, val_labels,\n",
        "                            quality_parameter=1.8, retrain_epochs=80, batch_size=32)\n",
        "\n",
        "# Evaluate the pruned model\n",
        "val_loss, val_accuracy = pruned_model.evaluate(val_images, val_labels, batch_size=128)\n",
        "print(f\"Validation Accuracy: {val_accuracy}\")\n",
        "\n",
        "# Calculate the total number of weights\n",
        "total_weights = np.sum([np.prod(w.shape) for w in pruned_weights])\n",
        "\n",
        "# Calculate the number of zero weights (sparsity)\n",
        "num_zero_weights = np.sum([np.count_nonzero(w == 0) for w in pruned_weights])\n",
        "sparsity = num_zero_weights / total_weights\n",
        "print(f\"Sparsity: {sparsity}\")\n",
        "\n",
        "# Calculate the score based on the provided formula\n",
        "if val_accuracy > 0.6 and sparsity > 0:\n",
        "    score = (val_accuracy + sparsity) / 2\n",
        "else:\n",
        "    score = 0\n",
        "\n",
        "print(f\"Model Score: {score}\")"
      ],
      "metadata": {
        "id": "ri4rCZRXLGxc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4e0b570-cc0a-4d47-d0e4-4d91eed8c869"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "703/703 [==============================] - 5s 5ms/step - loss: 1.5412 - accuracy: 0.2931 - val_loss: 1.3903 - val_accuracy: 0.3976\n",
            "Epoch 2/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.3513 - accuracy: 0.4202 - val_loss: 1.2649 - val_accuracy: 0.4709\n",
            "Epoch 3/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.2749 - accuracy: 0.4650 - val_loss: 1.1978 - val_accuracy: 0.5089\n",
            "Epoch 4/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.2241 - accuracy: 0.4881 - val_loss: 1.2109 - val_accuracy: 0.5026\n",
            "Epoch 5/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.1880 - accuracy: 0.5118 - val_loss: 1.1522 - val_accuracy: 0.5307\n",
            "Epoch 6/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.1588 - accuracy: 0.5266 - val_loss: 1.0870 - val_accuracy: 0.5628\n",
            "Epoch 7/80\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 1.1286 - accuracy: 0.5418 - val_loss: 1.0740 - val_accuracy: 0.5517\n",
            "Epoch 8/80\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 1.1108 - accuracy: 0.5477 - val_loss: 1.0434 - val_accuracy: 0.5762\n",
            "Epoch 9/80\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 1.0834 - accuracy: 0.5656 - val_loss: 1.0375 - val_accuracy: 0.5778\n",
            "Epoch 10/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.0692 - accuracy: 0.5696 - val_loss: 1.0117 - val_accuracy: 0.5826\n",
            "Epoch 11/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.0487 - accuracy: 0.5784 - val_loss: 1.0126 - val_accuracy: 0.5830\n",
            "Epoch 12/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.0312 - accuracy: 0.5907 - val_loss: 0.9741 - val_accuracy: 0.6055\n",
            "Epoch 13/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.0166 - accuracy: 0.5969 - val_loss: 1.0036 - val_accuracy: 0.5956\n",
            "Epoch 14/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9938 - accuracy: 0.6095 - val_loss: 0.9412 - val_accuracy: 0.6131\n",
            "Epoch 15/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9764 - accuracy: 0.6135 - val_loss: 0.9390 - val_accuracy: 0.6190\n",
            "Epoch 16/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9572 - accuracy: 0.6239 - val_loss: 0.9353 - val_accuracy: 0.6269\n",
            "Epoch 17/80\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 0.9436 - accuracy: 0.6319 - val_loss: 0.9062 - val_accuracy: 0.6349\n",
            "Epoch 18/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9290 - accuracy: 0.6380 - val_loss: 0.8849 - val_accuracy: 0.6444\n",
            "Epoch 19/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9196 - accuracy: 0.6421 - val_loss: 0.8734 - val_accuracy: 0.6503\n",
            "Epoch 20/80\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 0.9102 - accuracy: 0.6462 - val_loss: 0.8753 - val_accuracy: 0.6531\n",
            "Epoch 21/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.8900 - accuracy: 0.6554 - val_loss: 0.8470 - val_accuracy: 0.6677\n",
            "Epoch 22/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.8861 - accuracy: 0.6574 - val_loss: 0.8581 - val_accuracy: 0.6653\n",
            "Epoch 23/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.8728 - accuracy: 0.6640 - val_loss: 0.8480 - val_accuracy: 0.6650\n",
            "Epoch 24/80\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 0.8620 - accuracy: 0.6675 - val_loss: 0.8478 - val_accuracy: 0.6646\n",
            "Epoch 25/80\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 0.8555 - accuracy: 0.6688 - val_loss: 0.8479 - val_accuracy: 0.6547\n",
            "Epoch 26/80\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 0.8471 - accuracy: 0.6744 - val_loss: 0.8458 - val_accuracy: 0.6685\n",
            "Epoch 27/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.8306 - accuracy: 0.6803 - val_loss: 0.8480 - val_accuracy: 0.6614\n",
            "Epoch 28/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.8288 - accuracy: 0.6818 - val_loss: 0.8066 - val_accuracy: 0.6903\n",
            "Epoch 29/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.8134 - accuracy: 0.6900 - val_loss: 0.8054 - val_accuracy: 0.6895\n",
            "Epoch 30/80\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 0.8067 - accuracy: 0.6923 - val_loss: 0.8039 - val_accuracy: 0.6804\n",
            "Epoch 31/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.7974 - accuracy: 0.6923 - val_loss: 0.7929 - val_accuracy: 0.6943\n",
            "Epoch 32/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.7881 - accuracy: 0.6967 - val_loss: 0.7885 - val_accuracy: 0.6927\n",
            "Epoch 33/80\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 0.7764 - accuracy: 0.7007 - val_loss: 0.7760 - val_accuracy: 0.6950\n",
            "Epoch 34/80\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 0.7772 - accuracy: 0.7015 - val_loss: 0.7693 - val_accuracy: 0.7042\n",
            "Epoch 35/80\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 0.7679 - accuracy: 0.7053 - val_loss: 0.7749 - val_accuracy: 0.7006\n",
            "Epoch 36/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.7551 - accuracy: 0.7099 - val_loss: 0.7634 - val_accuracy: 0.7050\n",
            "Epoch 37/80\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 0.7476 - accuracy: 0.7143 - val_loss: 0.7676 - val_accuracy: 0.7097\n",
            "Epoch 38/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.7453 - accuracy: 0.7154 - val_loss: 0.7618 - val_accuracy: 0.7073\n",
            "Epoch 39/80\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 0.7377 - accuracy: 0.7174 - val_loss: 0.7606 - val_accuracy: 0.7081\n",
            "Epoch 40/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.7350 - accuracy: 0.7222 - val_loss: 0.7515 - val_accuracy: 0.7061\n",
            "Epoch 41/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.7245 - accuracy: 0.7252 - val_loss: 0.7607 - val_accuracy: 0.7089\n",
            "Epoch 42/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.7134 - accuracy: 0.7277 - val_loss: 0.7554 - val_accuracy: 0.7026\n",
            "Epoch 43/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.7114 - accuracy: 0.7295 - val_loss: 0.7696 - val_accuracy: 0.7030\n",
            "Epoch 44/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.7086 - accuracy: 0.7307 - val_loss: 0.7290 - val_accuracy: 0.7220\n",
            "Epoch 45/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6996 - accuracy: 0.7362 - val_loss: 0.7423 - val_accuracy: 0.7149\n",
            "Epoch 46/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6999 - accuracy: 0.7323 - val_loss: 0.7399 - val_accuracy: 0.7232\n",
            "Epoch 47/80\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 0.6886 - accuracy: 0.7402 - val_loss: 0.7507 - val_accuracy: 0.7125\n",
            "Epoch 48/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6758 - accuracy: 0.7455 - val_loss: 0.7326 - val_accuracy: 0.7188\n",
            "Epoch 49/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6802 - accuracy: 0.7456 - val_loss: 0.7346 - val_accuracy: 0.7248\n",
            "Epoch 50/80\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 0.6698 - accuracy: 0.7454 - val_loss: 0.7260 - val_accuracy: 0.7240\n",
            "Epoch 51/80\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 0.6636 - accuracy: 0.7471 - val_loss: 0.7346 - val_accuracy: 0.7244\n",
            "Epoch 52/80\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 0.6521 - accuracy: 0.7533 - val_loss: 0.7167 - val_accuracy: 0.7339\n",
            "Epoch 53/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6566 - accuracy: 0.7533 - val_loss: 0.7207 - val_accuracy: 0.7331\n",
            "Epoch 54/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6484 - accuracy: 0.7564 - val_loss: 0.7028 - val_accuracy: 0.7366\n",
            "Epoch 55/80\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 0.6456 - accuracy: 0.7579 - val_loss: 0.7318 - val_accuracy: 0.7279\n",
            "Epoch 56/80\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 0.6314 - accuracy: 0.7619 - val_loss: 0.7235 - val_accuracy: 0.7275\n",
            "Epoch 57/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6329 - accuracy: 0.7606 - val_loss: 0.6976 - val_accuracy: 0.7350\n",
            "Epoch 58/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6224 - accuracy: 0.7661 - val_loss: 0.7045 - val_accuracy: 0.7394\n",
            "Epoch 59/80\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 0.6189 - accuracy: 0.7693 - val_loss: 0.7325 - val_accuracy: 0.7212\n",
            "Epoch 60/80\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 0.6095 - accuracy: 0.7702 - val_loss: 0.7150 - val_accuracy: 0.7319\n",
            "Epoch 61/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6104 - accuracy: 0.7697 - val_loss: 0.7003 - val_accuracy: 0.7398\n",
            "Epoch 62/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6004 - accuracy: 0.7750 - val_loss: 0.7047 - val_accuracy: 0.7386\n",
            "Epoch 63/80\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 0.5956 - accuracy: 0.7741 - val_loss: 0.7006 - val_accuracy: 0.7418\n",
            "Epoch 64/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6015 - accuracy: 0.7719 - val_loss: 0.6926 - val_accuracy: 0.7481\n",
            "Epoch 65/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.5896 - accuracy: 0.7748 - val_loss: 0.6957 - val_accuracy: 0.7418\n",
            "Epoch 66/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.5815 - accuracy: 0.7794 - val_loss: 0.7065 - val_accuracy: 0.7386\n",
            "Epoch 67/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.5750 - accuracy: 0.7844 - val_loss: 0.7198 - val_accuracy: 0.7362\n",
            "Epoch 68/80\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 0.5722 - accuracy: 0.7865 - val_loss: 0.6874 - val_accuracy: 0.7521\n",
            "Epoch 69/80\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 0.5686 - accuracy: 0.7889 - val_loss: 0.7009 - val_accuracy: 0.7414\n",
            "Epoch 70/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.5621 - accuracy: 0.7874 - val_loss: 0.6962 - val_accuracy: 0.7446\n",
            "Epoch 71/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.5627 - accuracy: 0.7847 - val_loss: 0.6927 - val_accuracy: 0.7461\n",
            "Epoch 72/80\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 0.5521 - accuracy: 0.7921 - val_loss: 0.6998 - val_accuracy: 0.7398\n",
            "Epoch 73/80\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 0.5495 - accuracy: 0.7959 - val_loss: 0.6898 - val_accuracy: 0.7489\n",
            "Epoch 74/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.5440 - accuracy: 0.7983 - val_loss: 0.7109 - val_accuracy: 0.7390\n",
            "Epoch 75/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.5428 - accuracy: 0.7962 - val_loss: 0.6865 - val_accuracy: 0.7469\n",
            "Epoch 76/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.5345 - accuracy: 0.8011 - val_loss: 0.7028 - val_accuracy: 0.7457\n",
            "Epoch 77/80\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 0.5268 - accuracy: 0.8027 - val_loss: 0.7019 - val_accuracy: 0.7418\n",
            "Epoch 78/80\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 0.5252 - accuracy: 0.8076 - val_loss: 0.6967 - val_accuracy: 0.7513\n",
            "Epoch 79/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.5206 - accuracy: 0.8043 - val_loss: 0.6844 - val_accuracy: 0.7616\n",
            "Epoch 80/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.5141 - accuracy: 0.8069 - val_loss: 0.6976 - val_accuracy: 0.7549\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6976 - accuracy: 0.7549\n",
            "Validation Accuracy: 0.7548514604568481\n",
            "Sparsity: 0.9298740329851771\n",
            "Model Score: 0.8423627467210126\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMSKQW4k4T-G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3ea5dc68-a756-4e78-a3aa-8038f274aea5"
      },
      "source": [
        "# you need to save the model's weights, naming it 'my_model_weights.h5'\n",
        "model.save_weights(\"my_model_weights_2.h5\")\n",
        "\n",
        "# running this cell will immediately download a file called 'my_model_weights.h5'\n",
        "from google.colab import files\n",
        "files.download(\"my_model_weights_2.h5\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c41920c3-ac54-48ab-87b6-19263d7b6d3e\", \"my_model_weights_2.h5\", 2407040)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "L1-norm based filter pruning\n",
        "\n"
      ],
      "metadata": {
        "id": "wQUuxjmZAr3B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prune_and_finetune(model, train_images, train_labels, val_images, val_labels,\n",
        "                       pruning_rate=0.1, retrain_epochs=10, batch_size=128):\n",
        "    pruned_model = clone_model(model)\n",
        "    pruned_model.set_weights(model.get_weights())  # Copy weights from the original model\n",
        "\n",
        "    # Step 1: Calculate the L1-norm of each filter/neuron and prune\n",
        "    l1_norms = []\n",
        "    for layer in pruned_model.layers:\n",
        "        if isinstance(layer, (tf.keras.layers.Conv2D, tf.keras.layers.Dense)):\n",
        "            weights = layer.get_weights()[0]\n",
        "            if isinstance(layer, tf.keras.layers.Dense):\n",
        "                # Calculate norms per neuron for dense layers\n",
        "                norms = np.sum(np.abs(weights), axis=0)\n",
        "            else:\n",
        "                # Calculate norms per filter for Conv2D layers\n",
        "                norms = np.sum(np.abs(weights), axis=(0, 1, 2))\n",
        "            l1_norms.extend(norms)\n",
        "\n",
        "    threshold = np.percentile(l1_norms, pruning_rate * 100)\n",
        "\n",
        "    all_new_weights = []  # Use a different variable name for storing all layer weights\n",
        "    for layer in pruned_model.layers:\n",
        "        if isinstance(layer, (tf.keras.layers.Conv2D, tf.keras.layers.Dense)):\n",
        "            weights, biases = layer.get_weights()\n",
        "            if isinstance(layer, tf.keras.layers.Dense):\n",
        "                norms = np.sum(np.abs(weights), axis=0)\n",
        "            else:\n",
        "                norms = np.sum(np.abs(weights), axis=(0, 1, 2))\n",
        "            pruned_weights = np.where(norms < threshold, 0, weights)  # Use a different name here\n",
        "            all_new_weights.append([pruned_weights, biases])  # Append pruned weights and biases\n",
        "        else:\n",
        "            all_new_weights.append(layer.get_weights())\n",
        "\n",
        "    # Set the pruned weights to the model\n",
        "    for i, layer in enumerate(pruned_model.layers):\n",
        "        if layer.get_weights():\n",
        "            layer.set_weights(all_new_weights[i])\n",
        "\n",
        "    # Step 2: Retrain the network\n",
        "    pruned_model.compile(optimizer='adam',\n",
        "                         loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "                         metrics=['accuracy'])\n",
        "\n",
        "    # reduce the learning rate for retraining\n",
        "    old_lr = tf.keras.backend.get_value(pruned_model.optimizer.lr)\n",
        "    new_lr = old_lr * 0.1\n",
        "    tf.keras.backend.set_value(pruned_model.optimizer.lr, new_lr)\n",
        "\n",
        "    history = pruned_model.fit(train_images, train_labels,\n",
        "                               batch_size=batch_size,\n",
        "                               epochs=retrain_epochs,\n",
        "                               validation_data=(val_images, val_labels))\n",
        "\n",
        "    # restore the original learning rate\n",
        "    tf.keras.backend.set_value(pruned_model.optimizer.lr, old_lr)\n",
        "\n",
        "    # Return the history for analysis and the model with pruned and fine-tuned weights\n",
        "    return history, pruned_model\n",
        "\n",
        "\n",
        "\n",
        "history, pruned_model = prune_and_finetune(model, train_images, train_labels, val_images, val_labels,\n",
        "                            pruning_rate=0.7, retrain_epochs=80, batch_size=32)\n",
        "\n",
        "# Evaluate the pruned model\n",
        "val_loss, val_accuracy = pruned_model.evaluate(val_images, val_labels, batch_size=128)\n",
        "print(f\"Validation Accuracy: {val_accuracy}\")\n",
        "\n",
        "total_weights = 0\n",
        "zero_weights = 0\n",
        "for layer in pruned_model.layers:\n",
        "    if isinstance(layer, (tf.keras.layers.Conv2D, tf.keras.layers.Dense)):\n",
        "        weights = layer.get_weights()[0]  # Get filter weights\n",
        "        biases = layer.get_weights()[1]\n",
        "        total_weights += np.size(weights) + np.size(biases)\n",
        "        zero_weights += np.count_nonzero(weights == 0)\n",
        "\n",
        "sparsity = zero_weights / total_weights\n",
        "print(f\"Sparsity: {sparsity}\")\n",
        "\n",
        "# Calculate the score based on the provided formula\n",
        "if val_accuracy > 0.6 and sparsity > 0:\n",
        "    score = (val_accuracy + sparsity) / 2\n",
        "else:\n",
        "    score = 0\n",
        "\n",
        "print(f\"Model Score: {score}\")\n"
      ],
      "metadata": {
        "id": "EHH_s4rE1p5l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36362497-91bb-48f6-cc4e-d1b3b5018b42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "703/703 [==============================] - 5s 5ms/step - loss: 1.6150 - accuracy: 0.1993 - val_loss: 1.5962 - val_accuracy: 0.2396\n",
            "Epoch 2/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.5448 - accuracy: 0.2893 - val_loss: 1.4984 - val_accuracy: 0.3156\n",
            "Epoch 3/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.4951 - accuracy: 0.3229 - val_loss: 1.4557 - val_accuracy: 0.3426\n",
            "Epoch 4/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.4470 - accuracy: 0.3584 - val_loss: 1.4018 - val_accuracy: 0.3933\n",
            "Epoch 5/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.4145 - accuracy: 0.3767 - val_loss: 1.3696 - val_accuracy: 0.4182\n",
            "Epoch 6/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.3825 - accuracy: 0.3984 - val_loss: 1.3374 - val_accuracy: 0.4333\n",
            "Epoch 7/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.3538 - accuracy: 0.4144 - val_loss: 1.3121 - val_accuracy: 0.4471\n",
            "Epoch 8/80\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 1.3285 - accuracy: 0.4299 - val_loss: 1.2915 - val_accuracy: 0.4483\n",
            "Epoch 9/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.3113 - accuracy: 0.4412 - val_loss: 1.2738 - val_accuracy: 0.4610\n",
            "Epoch 10/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.2976 - accuracy: 0.4502 - val_loss: 1.2445 - val_accuracy: 0.4776\n",
            "Epoch 11/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.2852 - accuracy: 0.4565 - val_loss: 1.2306 - val_accuracy: 0.4840\n",
            "Epoch 12/80\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 1.2616 - accuracy: 0.4688 - val_loss: 1.2197 - val_accuracy: 0.4800\n",
            "Epoch 13/80\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 1.2551 - accuracy: 0.4698 - val_loss: 1.2090 - val_accuracy: 0.4923\n",
            "Epoch 14/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.2434 - accuracy: 0.4771 - val_loss: 1.2043 - val_accuracy: 0.4998\n",
            "Epoch 15/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.2359 - accuracy: 0.4851 - val_loss: 1.1918 - val_accuracy: 0.5014\n",
            "Epoch 16/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.2240 - accuracy: 0.4885 - val_loss: 1.2064 - val_accuracy: 0.4939\n",
            "Epoch 17/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.2244 - accuracy: 0.4912 - val_loss: 1.1843 - val_accuracy: 0.5125\n",
            "Epoch 18/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.2120 - accuracy: 0.4939 - val_loss: 1.1662 - val_accuracy: 0.5160\n",
            "Epoch 19/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.2089 - accuracy: 0.4994 - val_loss: 1.1646 - val_accuracy: 0.5192\n",
            "Epoch 20/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.1976 - accuracy: 0.5055 - val_loss: 1.1745 - val_accuracy: 0.5164\n",
            "Epoch 21/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.1907 - accuracy: 0.5095 - val_loss: 1.1596 - val_accuracy: 0.5248\n",
            "Epoch 22/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.1848 - accuracy: 0.5132 - val_loss: 1.1633 - val_accuracy: 0.5287\n",
            "Epoch 23/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.1770 - accuracy: 0.5153 - val_loss: 1.1442 - val_accuracy: 0.5299\n",
            "Epoch 24/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.1748 - accuracy: 0.5157 - val_loss: 1.1375 - val_accuracy: 0.5275\n",
            "Epoch 25/80\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 1.1668 - accuracy: 0.5220 - val_loss: 1.1385 - val_accuracy: 0.5343\n",
            "Epoch 26/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.1601 - accuracy: 0.5279 - val_loss: 1.1340 - val_accuracy: 0.5386\n",
            "Epoch 27/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.1573 - accuracy: 0.5293 - val_loss: 1.1249 - val_accuracy: 0.5311\n",
            "Epoch 28/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.1520 - accuracy: 0.5299 - val_loss: 1.1258 - val_accuracy: 0.5331\n",
            "Epoch 29/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.1422 - accuracy: 0.5370 - val_loss: 1.1170 - val_accuracy: 0.5414\n",
            "Epoch 30/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.1385 - accuracy: 0.5401 - val_loss: 1.1171 - val_accuracy: 0.5390\n",
            "Epoch 31/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.1326 - accuracy: 0.5417 - val_loss: 1.1143 - val_accuracy: 0.5398\n",
            "Epoch 32/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.1307 - accuracy: 0.5416 - val_loss: 1.1114 - val_accuracy: 0.5422\n",
            "Epoch 33/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.1178 - accuracy: 0.5476 - val_loss: 1.0998 - val_accuracy: 0.5537\n",
            "Epoch 34/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.1155 - accuracy: 0.5511 - val_loss: 1.1054 - val_accuracy: 0.5497\n",
            "Epoch 35/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.1088 - accuracy: 0.5527 - val_loss: 1.1029 - val_accuracy: 0.5541\n",
            "Epoch 36/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.1057 - accuracy: 0.5535 - val_loss: 1.0903 - val_accuracy: 0.5596\n",
            "Epoch 37/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.0985 - accuracy: 0.5581 - val_loss: 1.0838 - val_accuracy: 0.5616\n",
            "Epoch 38/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.0904 - accuracy: 0.5622 - val_loss: 1.0844 - val_accuracy: 0.5549\n",
            "Epoch 39/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.0876 - accuracy: 0.5612 - val_loss: 1.0866 - val_accuracy: 0.5533\n",
            "Epoch 40/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.0870 - accuracy: 0.5623 - val_loss: 1.0851 - val_accuracy: 0.5513\n",
            "Epoch 41/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.0786 - accuracy: 0.5689 - val_loss: 1.0891 - val_accuracy: 0.5572\n",
            "Epoch 42/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.0730 - accuracy: 0.5683 - val_loss: 1.0781 - val_accuracy: 0.5576\n",
            "Epoch 43/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.0700 - accuracy: 0.5724 - val_loss: 1.0670 - val_accuracy: 0.5620\n",
            "Epoch 44/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.0667 - accuracy: 0.5709 - val_loss: 1.0720 - val_accuracy: 0.5600\n",
            "Epoch 45/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.0593 - accuracy: 0.5749 - val_loss: 1.0749 - val_accuracy: 0.5655\n",
            "Epoch 46/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.0598 - accuracy: 0.5780 - val_loss: 1.0659 - val_accuracy: 0.5758\n",
            "Epoch 47/80\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 1.0513 - accuracy: 0.5803 - val_loss: 1.0629 - val_accuracy: 0.5707\n",
            "Epoch 48/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.0439 - accuracy: 0.5822 - val_loss: 1.0617 - val_accuracy: 0.5703\n",
            "Epoch 49/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.0433 - accuracy: 0.5871 - val_loss: 1.0705 - val_accuracy: 0.5667\n",
            "Epoch 50/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.0381 - accuracy: 0.5855 - val_loss: 1.0566 - val_accuracy: 0.5806\n",
            "Epoch 51/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.0287 - accuracy: 0.5929 - val_loss: 1.0546 - val_accuracy: 0.5758\n",
            "Epoch 52/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.0229 - accuracy: 0.5917 - val_loss: 1.0558 - val_accuracy: 0.5671\n",
            "Epoch 53/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.0191 - accuracy: 0.5959 - val_loss: 1.0566 - val_accuracy: 0.5699\n",
            "Epoch 54/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.0155 - accuracy: 0.5970 - val_loss: 1.0494 - val_accuracy: 0.5723\n",
            "Epoch 55/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.0124 - accuracy: 0.5972 - val_loss: 1.0523 - val_accuracy: 0.5786\n",
            "Epoch 56/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9988 - accuracy: 0.6046 - val_loss: 1.0383 - val_accuracy: 0.5901\n",
            "Epoch 57/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.0038 - accuracy: 0.6035 - val_loss: 1.0498 - val_accuracy: 0.5857\n",
            "Epoch 58/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9948 - accuracy: 0.6053 - val_loss: 1.0469 - val_accuracy: 0.5806\n",
            "Epoch 59/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9921 - accuracy: 0.6048 - val_loss: 1.0464 - val_accuracy: 0.5786\n",
            "Epoch 60/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9908 - accuracy: 0.6096 - val_loss: 1.0388 - val_accuracy: 0.5818\n",
            "Epoch 61/80\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 0.9868 - accuracy: 0.6097 - val_loss: 1.0378 - val_accuracy: 0.5838\n",
            "Epoch 62/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9822 - accuracy: 0.6140 - val_loss: 1.0344 - val_accuracy: 0.5770\n",
            "Epoch 63/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9721 - accuracy: 0.6158 - val_loss: 1.0366 - val_accuracy: 0.5798\n",
            "Epoch 64/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9735 - accuracy: 0.6162 - val_loss: 1.0303 - val_accuracy: 0.5850\n",
            "Epoch 65/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9685 - accuracy: 0.6198 - val_loss: 1.0291 - val_accuracy: 0.5952\n",
            "Epoch 66/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9651 - accuracy: 0.6209 - val_loss: 1.0281 - val_accuracy: 0.5956\n",
            "Epoch 67/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9608 - accuracy: 0.6199 - val_loss: 1.0264 - val_accuracy: 0.5881\n",
            "Epoch 68/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9581 - accuracy: 0.6235 - val_loss: 1.0274 - val_accuracy: 0.5929\n",
            "Epoch 69/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9554 - accuracy: 0.6227 - val_loss: 1.0199 - val_accuracy: 0.5952\n",
            "Epoch 70/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9521 - accuracy: 0.6300 - val_loss: 1.0279 - val_accuracy: 0.5869\n",
            "Epoch 71/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9544 - accuracy: 0.6235 - val_loss: 1.0280 - val_accuracy: 0.5850\n",
            "Epoch 72/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9356 - accuracy: 0.6305 - val_loss: 1.0213 - val_accuracy: 0.5921\n",
            "Epoch 73/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9421 - accuracy: 0.6289 - val_loss: 1.0266 - val_accuracy: 0.5925\n",
            "Epoch 74/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9278 - accuracy: 0.6344 - val_loss: 1.0288 - val_accuracy: 0.5925\n",
            "Epoch 75/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9371 - accuracy: 0.6303 - val_loss: 1.0252 - val_accuracy: 0.5909\n",
            "Epoch 76/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9262 - accuracy: 0.6365 - val_loss: 1.0099 - val_accuracy: 0.5952\n",
            "Epoch 77/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9215 - accuracy: 0.6405 - val_loss: 1.0152 - val_accuracy: 0.5941\n",
            "Epoch 78/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9207 - accuracy: 0.6386 - val_loss: 1.0101 - val_accuracy: 0.5952\n",
            "Epoch 79/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9170 - accuracy: 0.6384 - val_loss: 1.0109 - val_accuracy: 0.5996\n",
            "Epoch 80/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9171 - accuracy: 0.6442 - val_loss: 1.0085 - val_accuracy: 0.5972\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 1.0085 - accuracy: 0.5972\n",
            "Validation Accuracy: 0.5972277522087097\n",
            "Sparsity: 0.3658946289041089\n",
            "Model Score: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "L1-norm based filter pruning - Gradual Pruning with Fine-Tuning"
      ],
      "metadata": {
        "id": "USwBSaOZO3sf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gradual_prune_and_finetune(model, train_images, train_labels, val_images, val_labels,\n",
        "                               initial_pruning_rate=0.1, pruning_steps=5, retrain_epochs=10, batch_size=128):\n",
        "    pruned_model = clone_model(model)\n",
        "    pruned_model.set_weights(model.get_weights())  # Copy weights from the original model\n",
        "\n",
        "    for step in range(pruning_steps):\n",
        "        current_pruning_rate = initial_pruning_rate * (step + 1) / pruning_steps\n",
        "\n",
        "        # Step 1: Prune the network\n",
        "        for layer in pruned_model.layers:\n",
        "            if isinstance(layer, (tf.keras.layers.Conv2D, tf.keras.layers.Dense)):\n",
        "                weights, biases = layer.get_weights()\n",
        "                if isinstance(layer, tf.keras.layers.Dense):\n",
        "                    norms = np.sum(np.abs(weights), axis=0)\n",
        "                else:  # Conv2D\n",
        "                    norms = np.sum(np.abs(weights), axis=(0, 1, 2))\n",
        "\n",
        "                threshold = np.percentile(norms, current_pruning_rate * 100)\n",
        "                new_weights = np.where(norms < threshold, 0, weights)\n",
        "                layer.set_weights([new_weights, biases])\n",
        "\n",
        "        # Step 2: Retrain the network\n",
        "        pruned_model.compile(optimizer='adam',\n",
        "                             loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "                             metrics=['accuracy'])\n",
        "        pruned_model.fit(train_images, train_labels, batch_size=batch_size, epochs=retrain_epochs,\n",
        "                         validation_data=(val_images, val_labels))\n",
        "\n",
        "    return pruned_model\n",
        "\n",
        "pruned_model = gradual_prune_and_finetune(model, train_images, train_labels, val_images, val_labels,\n",
        "                                          initial_pruning_rate=0.9, pruning_steps=3, retrain_epochs=80, batch_size=32)\n",
        "\n",
        "# Evaluate the pruned model\n",
        "val_loss, val_accuracy = pruned_model.evaluate(val_images, val_labels, batch_size=128)\n",
        "print(f\"Validation Accuracy after pruning: {val_accuracy}\")\n",
        "\n",
        "# Calculate sparsity\n",
        "total_weights = 0\n",
        "zero_weights = 0\n",
        "for layer in pruned_model.layers:\n",
        "    if isinstance(layer, (tf.keras.layers.Conv2D, tf.keras.layers.Dense)):\n",
        "        weights, biases = layer.get_weights()\n",
        "        total_weights += np.size(weights) + np.size(biases)\n",
        "        zero_weights += np.count_nonzero(weights == 0)\n",
        "\n",
        "sparsity = zero_weights / total_weights\n",
        "print(f\"Sparsity: {sparsity}\")\n",
        "\n",
        "# Calculate the model score\n",
        "if val_accuracy > 0.6 and sparsity > 0:\n",
        "    score = (val_accuracy + sparsity) / 2\n",
        "else:\n",
        "    score = 0\n",
        "\n",
        "print(f\"Model Score: {score}\")"
      ],
      "metadata": {
        "id": "O6RHVucdAg0P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b1b5ea5-35b1-459b-f954-47e811a55019"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "703/703 [==============================] - 5s 5ms/step - loss: 1.0151 - accuracy: 0.5998 - val_loss: 0.8604 - val_accuracy: 0.6697\n",
            "Epoch 2/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.8634 - accuracy: 0.6665 - val_loss: 0.9068 - val_accuracy: 0.6479\n",
            "Epoch 3/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.8109 - accuracy: 0.6935 - val_loss: 0.7862 - val_accuracy: 0.7006\n",
            "Epoch 4/80\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 0.7836 - accuracy: 0.7022 - val_loss: 0.7583 - val_accuracy: 0.7093\n",
            "Epoch 5/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.7515 - accuracy: 0.7132 - val_loss: 0.7307 - val_accuracy: 0.7236\n",
            "Epoch 6/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.7309 - accuracy: 0.7249 - val_loss: 0.7460 - val_accuracy: 0.7251\n",
            "Epoch 7/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.7156 - accuracy: 0.7293 - val_loss: 0.7654 - val_accuracy: 0.7042\n",
            "Epoch 8/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6874 - accuracy: 0.7401 - val_loss: 0.7175 - val_accuracy: 0.7220\n",
            "Epoch 9/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6658 - accuracy: 0.7448 - val_loss: 0.7546 - val_accuracy: 0.7208\n",
            "Epoch 10/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6507 - accuracy: 0.7541 - val_loss: 0.7066 - val_accuracy: 0.7350\n",
            "Epoch 11/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6411 - accuracy: 0.7590 - val_loss: 0.7219 - val_accuracy: 0.7271\n",
            "Epoch 12/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6213 - accuracy: 0.7684 - val_loss: 0.7251 - val_accuracy: 0.7390\n",
            "Epoch 13/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6071 - accuracy: 0.7737 - val_loss: 0.7005 - val_accuracy: 0.7390\n",
            "Epoch 14/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.5901 - accuracy: 0.7800 - val_loss: 0.7132 - val_accuracy: 0.7362\n",
            "Epoch 15/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.5872 - accuracy: 0.7816 - val_loss: 0.7000 - val_accuracy: 0.7430\n",
            "Epoch 16/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.5750 - accuracy: 0.7859 - val_loss: 0.7161 - val_accuracy: 0.7390\n",
            "Epoch 17/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.5652 - accuracy: 0.7871 - val_loss: 0.7032 - val_accuracy: 0.7394\n",
            "Epoch 18/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.5556 - accuracy: 0.7964 - val_loss: 0.7017 - val_accuracy: 0.7469\n",
            "Epoch 19/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.5487 - accuracy: 0.7956 - val_loss: 0.6908 - val_accuracy: 0.7461\n",
            "Epoch 20/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.5436 - accuracy: 0.7983 - val_loss: 0.7262 - val_accuracy: 0.7327\n",
            "Epoch 21/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.5280 - accuracy: 0.8027 - val_loss: 0.7424 - val_accuracy: 0.7299\n",
            "Epoch 22/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.5299 - accuracy: 0.8031 - val_loss: 0.7171 - val_accuracy: 0.7366\n",
            "Epoch 23/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.5161 - accuracy: 0.8083 - val_loss: 0.7015 - val_accuracy: 0.7525\n",
            "Epoch 24/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.5190 - accuracy: 0.8087 - val_loss: 0.6974 - val_accuracy: 0.7497\n",
            "Epoch 25/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.5032 - accuracy: 0.8158 - val_loss: 0.7032 - val_accuracy: 0.7390\n",
            "Epoch 26/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.4964 - accuracy: 0.8205 - val_loss: 0.7377 - val_accuracy: 0.7390\n",
            "Epoch 27/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.4960 - accuracy: 0.8191 - val_loss: 0.7166 - val_accuracy: 0.7410\n",
            "Epoch 28/80\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 0.4831 - accuracy: 0.8215 - val_loss: 0.7095 - val_accuracy: 0.7517\n",
            "Epoch 29/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.4948 - accuracy: 0.8202 - val_loss: 0.6848 - val_accuracy: 0.7541\n",
            "Epoch 30/80\n",
            "703/703 [==============================] - 4s 5ms/step - loss: 0.4775 - accuracy: 0.8245 - val_loss: 0.7080 - val_accuracy: 0.7473\n",
            "Epoch 31/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.4806 - accuracy: 0.8239 - val_loss: 0.7111 - val_accuracy: 0.7541\n",
            "Epoch 32/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.4633 - accuracy: 0.8324 - val_loss: 0.7425 - val_accuracy: 0.7434\n",
            "Epoch 33/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.4577 - accuracy: 0.8326 - val_loss: 0.7230 - val_accuracy: 0.7465\n",
            "Epoch 34/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.4632 - accuracy: 0.8324 - val_loss: 0.7025 - val_accuracy: 0.7549\n",
            "Epoch 35/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.4534 - accuracy: 0.8371 - val_loss: 0.7199 - val_accuracy: 0.7576\n",
            "Epoch 36/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.4594 - accuracy: 0.8339 - val_loss: 0.7718 - val_accuracy: 0.7386\n",
            "Epoch 37/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.4476 - accuracy: 0.8379 - val_loss: 0.7265 - val_accuracy: 0.7537\n",
            "Epoch 38/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.4462 - accuracy: 0.8385 - val_loss: 0.7015 - val_accuracy: 0.7608\n",
            "Epoch 39/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.4387 - accuracy: 0.8422 - val_loss: 0.7254 - val_accuracy: 0.7572\n",
            "Epoch 40/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.4446 - accuracy: 0.8380 - val_loss: 0.6872 - val_accuracy: 0.7628\n",
            "Epoch 41/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.4338 - accuracy: 0.8447 - val_loss: 0.7060 - val_accuracy: 0.7584\n",
            "Epoch 42/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.4332 - accuracy: 0.8470 - val_loss: 0.7689 - val_accuracy: 0.7517\n",
            "Epoch 43/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.4316 - accuracy: 0.8445 - val_loss: 0.7150 - val_accuracy: 0.7560\n",
            "Epoch 44/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.4466 - accuracy: 0.8404 - val_loss: 0.7492 - val_accuracy: 0.7406\n",
            "Epoch 45/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.4302 - accuracy: 0.8485 - val_loss: 0.7311 - val_accuracy: 0.7556\n",
            "Epoch 46/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.4262 - accuracy: 0.8482 - val_loss: 0.7638 - val_accuracy: 0.7414\n",
            "Epoch 47/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.4270 - accuracy: 0.8457 - val_loss: 0.7229 - val_accuracy: 0.7592\n",
            "Epoch 48/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.4230 - accuracy: 0.8511 - val_loss: 0.6791 - val_accuracy: 0.7671\n",
            "Epoch 49/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.4161 - accuracy: 0.8535 - val_loss: 0.7612 - val_accuracy: 0.7418\n",
            "Epoch 50/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.4137 - accuracy: 0.8515 - val_loss: 0.7235 - val_accuracy: 0.7469\n",
            "Epoch 51/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.4047 - accuracy: 0.8562 - val_loss: 0.7061 - val_accuracy: 0.7533\n",
            "Epoch 52/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.4075 - accuracy: 0.8570 - val_loss: 0.7072 - val_accuracy: 0.7592\n",
            "Epoch 53/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.4111 - accuracy: 0.8525 - val_loss: 0.7248 - val_accuracy: 0.7537\n",
            "Epoch 54/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.4164 - accuracy: 0.8513 - val_loss: 0.6974 - val_accuracy: 0.7648\n",
            "Epoch 55/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.4061 - accuracy: 0.8565 - val_loss: 0.7579 - val_accuracy: 0.7505\n",
            "Epoch 56/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.4101 - accuracy: 0.8537 - val_loss: 0.7089 - val_accuracy: 0.7560\n",
            "Epoch 57/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.3945 - accuracy: 0.8574 - val_loss: 0.7515 - val_accuracy: 0.7568\n",
            "Epoch 58/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.4046 - accuracy: 0.8567 - val_loss: 0.7324 - val_accuracy: 0.7457\n",
            "Epoch 59/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.4042 - accuracy: 0.8581 - val_loss: 0.7285 - val_accuracy: 0.7576\n",
            "Epoch 60/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.3923 - accuracy: 0.8611 - val_loss: 0.7726 - val_accuracy: 0.7497\n",
            "Epoch 61/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.4114 - accuracy: 0.8568 - val_loss: 0.7628 - val_accuracy: 0.7430\n",
            "Epoch 62/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.3926 - accuracy: 0.8602 - val_loss: 0.7352 - val_accuracy: 0.7545\n",
            "Epoch 63/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.3894 - accuracy: 0.8651 - val_loss: 0.7509 - val_accuracy: 0.7517\n",
            "Epoch 64/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.3930 - accuracy: 0.8633 - val_loss: 0.7762 - val_accuracy: 0.7596\n",
            "Epoch 65/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.3913 - accuracy: 0.8629 - val_loss: 0.7386 - val_accuracy: 0.7541\n",
            "Epoch 66/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.3918 - accuracy: 0.8642 - val_loss: 0.7679 - val_accuracy: 0.7473\n",
            "Epoch 67/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.3906 - accuracy: 0.8645 - val_loss: 0.8266 - val_accuracy: 0.7251\n",
            "Epoch 68/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.3835 - accuracy: 0.8635 - val_loss: 0.7761 - val_accuracy: 0.7450\n",
            "Epoch 69/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.3913 - accuracy: 0.8630 - val_loss: 0.7424 - val_accuracy: 0.7620\n",
            "Epoch 70/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.3905 - accuracy: 0.8634 - val_loss: 0.7371 - val_accuracy: 0.7545\n",
            "Epoch 71/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.3815 - accuracy: 0.8684 - val_loss: 0.7334 - val_accuracy: 0.7533\n",
            "Epoch 72/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.3799 - accuracy: 0.8675 - val_loss: 0.7400 - val_accuracy: 0.7655\n",
            "Epoch 73/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.3860 - accuracy: 0.8645 - val_loss: 0.7573 - val_accuracy: 0.7529\n",
            "Epoch 74/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.3735 - accuracy: 0.8693 - val_loss: 0.7514 - val_accuracy: 0.7501\n",
            "Epoch 75/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.3777 - accuracy: 0.8709 - val_loss: 0.7517 - val_accuracy: 0.7465\n",
            "Epoch 76/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.3770 - accuracy: 0.8723 - val_loss: 0.7462 - val_accuracy: 0.7501\n",
            "Epoch 77/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.3698 - accuracy: 0.8696 - val_loss: 0.7613 - val_accuracy: 0.7533\n",
            "Epoch 78/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.3691 - accuracy: 0.8719 - val_loss: 0.7850 - val_accuracy: 0.7335\n",
            "Epoch 79/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.3809 - accuracy: 0.8696 - val_loss: 0.7250 - val_accuracy: 0.7560\n",
            "Epoch 80/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.3690 - accuracy: 0.8725 - val_loss: 0.7541 - val_accuracy: 0.7651\n",
            "Epoch 1/80\n",
            "703/703 [==============================] - 5s 5ms/step - loss: 1.2157 - accuracy: 0.5099 - val_loss: 0.9943 - val_accuracy: 0.6123\n",
            "Epoch 2/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9727 - accuracy: 0.6273 - val_loss: 0.8975 - val_accuracy: 0.6582\n",
            "Epoch 3/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9033 - accuracy: 0.6584 - val_loss: 0.8619 - val_accuracy: 0.6725\n",
            "Epoch 4/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.8669 - accuracy: 0.6692 - val_loss: 0.8152 - val_accuracy: 0.6970\n",
            "Epoch 5/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.8439 - accuracy: 0.6840 - val_loss: 0.7735 - val_accuracy: 0.7145\n",
            "Epoch 6/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.8084 - accuracy: 0.6962 - val_loss: 0.7789 - val_accuracy: 0.7097\n",
            "Epoch 7/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.7917 - accuracy: 0.7032 - val_loss: 0.7592 - val_accuracy: 0.7125\n",
            "Epoch 8/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.7738 - accuracy: 0.7090 - val_loss: 0.7900 - val_accuracy: 0.7061\n",
            "Epoch 9/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.7642 - accuracy: 0.7171 - val_loss: 0.7536 - val_accuracy: 0.7220\n",
            "Epoch 10/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.7544 - accuracy: 0.7172 - val_loss: 0.7817 - val_accuracy: 0.7101\n",
            "Epoch 11/80\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 0.7443 - accuracy: 0.7212 - val_loss: 0.7571 - val_accuracy: 0.7224\n",
            "Epoch 12/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.7345 - accuracy: 0.7273 - val_loss: 0.7519 - val_accuracy: 0.7192\n",
            "Epoch 13/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.7269 - accuracy: 0.7317 - val_loss: 0.7734 - val_accuracy: 0.7152\n",
            "Epoch 14/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.7220 - accuracy: 0.7325 - val_loss: 0.7715 - val_accuracy: 0.7053\n",
            "Epoch 15/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.7183 - accuracy: 0.7315 - val_loss: 0.7368 - val_accuracy: 0.7263\n",
            "Epoch 16/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.7018 - accuracy: 0.7382 - val_loss: 0.7442 - val_accuracy: 0.7212\n",
            "Epoch 17/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.7000 - accuracy: 0.7393 - val_loss: 0.7232 - val_accuracy: 0.7327\n",
            "Epoch 18/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6892 - accuracy: 0.7413 - val_loss: 0.7261 - val_accuracy: 0.7358\n",
            "Epoch 19/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6911 - accuracy: 0.7435 - val_loss: 0.7646 - val_accuracy: 0.7180\n",
            "Epoch 20/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6877 - accuracy: 0.7458 - val_loss: 0.7238 - val_accuracy: 0.7287\n",
            "Epoch 21/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6779 - accuracy: 0.7513 - val_loss: 0.7336 - val_accuracy: 0.7267\n",
            "Epoch 22/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6690 - accuracy: 0.7499 - val_loss: 0.7606 - val_accuracy: 0.7204\n",
            "Epoch 23/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6764 - accuracy: 0.7478 - val_loss: 0.7216 - val_accuracy: 0.7331\n",
            "Epoch 24/80\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 0.6598 - accuracy: 0.7537 - val_loss: 0.7087 - val_accuracy: 0.7453\n",
            "Epoch 25/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6660 - accuracy: 0.7523 - val_loss: 0.7184 - val_accuracy: 0.7366\n",
            "Epoch 26/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6596 - accuracy: 0.7542 - val_loss: 0.7072 - val_accuracy: 0.7501\n",
            "Epoch 27/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6593 - accuracy: 0.7569 - val_loss: 0.7969 - val_accuracy: 0.7109\n",
            "Epoch 28/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6628 - accuracy: 0.7506 - val_loss: 0.7255 - val_accuracy: 0.7323\n",
            "Epoch 29/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6523 - accuracy: 0.7564 - val_loss: 0.7911 - val_accuracy: 0.7133\n",
            "Epoch 30/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6478 - accuracy: 0.7561 - val_loss: 0.7407 - val_accuracy: 0.7255\n",
            "Epoch 31/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6543 - accuracy: 0.7580 - val_loss: 0.7278 - val_accuracy: 0.7307\n",
            "Epoch 32/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6440 - accuracy: 0.7620 - val_loss: 0.7704 - val_accuracy: 0.7192\n",
            "Epoch 33/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6313 - accuracy: 0.7662 - val_loss: 0.7805 - val_accuracy: 0.7093\n",
            "Epoch 34/80\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 0.6486 - accuracy: 0.7596 - val_loss: 0.7114 - val_accuracy: 0.7370\n",
            "Epoch 35/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6312 - accuracy: 0.7649 - val_loss: 0.7043 - val_accuracy: 0.7430\n",
            "Epoch 36/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6293 - accuracy: 0.7661 - val_loss: 0.7556 - val_accuracy: 0.7200\n",
            "Epoch 37/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6288 - accuracy: 0.7656 - val_loss: 0.7423 - val_accuracy: 0.7307\n",
            "Epoch 38/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6287 - accuracy: 0.7661 - val_loss: 0.7242 - val_accuracy: 0.7374\n",
            "Epoch 39/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6237 - accuracy: 0.7686 - val_loss: 0.7278 - val_accuracy: 0.7414\n",
            "Epoch 40/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6254 - accuracy: 0.7681 - val_loss: 0.7104 - val_accuracy: 0.7453\n",
            "Epoch 41/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6227 - accuracy: 0.7680 - val_loss: 0.7564 - val_accuracy: 0.7303\n",
            "Epoch 42/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6233 - accuracy: 0.7688 - val_loss: 0.7804 - val_accuracy: 0.7129\n",
            "Epoch 43/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6258 - accuracy: 0.7703 - val_loss: 0.7058 - val_accuracy: 0.7450\n",
            "Epoch 44/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6199 - accuracy: 0.7652 - val_loss: 0.7233 - val_accuracy: 0.7386\n",
            "Epoch 45/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6166 - accuracy: 0.7684 - val_loss: 0.7581 - val_accuracy: 0.7287\n",
            "Epoch 46/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6080 - accuracy: 0.7743 - val_loss: 0.7206 - val_accuracy: 0.7386\n",
            "Epoch 47/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6078 - accuracy: 0.7734 - val_loss: 0.7244 - val_accuracy: 0.7327\n",
            "Epoch 48/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6129 - accuracy: 0.7717 - val_loss: 0.7402 - val_accuracy: 0.7354\n",
            "Epoch 49/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6115 - accuracy: 0.7736 - val_loss: 0.8147 - val_accuracy: 0.7164\n",
            "Epoch 50/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6109 - accuracy: 0.7730 - val_loss: 0.7338 - val_accuracy: 0.7287\n",
            "Epoch 51/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.5994 - accuracy: 0.7784 - val_loss: 0.7173 - val_accuracy: 0.7457\n",
            "Epoch 52/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6045 - accuracy: 0.7749 - val_loss: 0.7134 - val_accuracy: 0.7453\n",
            "Epoch 53/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6008 - accuracy: 0.7759 - val_loss: 0.7704 - val_accuracy: 0.7255\n",
            "Epoch 54/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6093 - accuracy: 0.7746 - val_loss: 0.7447 - val_accuracy: 0.7303\n",
            "Epoch 55/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.5987 - accuracy: 0.7781 - val_loss: 0.7432 - val_accuracy: 0.7331\n",
            "Epoch 56/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6038 - accuracy: 0.7778 - val_loss: 0.7007 - val_accuracy: 0.7477\n",
            "Epoch 57/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.5953 - accuracy: 0.7821 - val_loss: 0.7382 - val_accuracy: 0.7303\n",
            "Epoch 58/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6023 - accuracy: 0.7776 - val_loss: 0.7099 - val_accuracy: 0.7568\n",
            "Epoch 59/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.5901 - accuracy: 0.7822 - val_loss: 0.7191 - val_accuracy: 0.7343\n",
            "Epoch 60/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6027 - accuracy: 0.7782 - val_loss: 0.7840 - val_accuracy: 0.7196\n",
            "Epoch 61/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.5954 - accuracy: 0.7799 - val_loss: 0.7311 - val_accuracy: 0.7390\n",
            "Epoch 62/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.5996 - accuracy: 0.7774 - val_loss: 0.7234 - val_accuracy: 0.7347\n",
            "Epoch 63/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.6000 - accuracy: 0.7780 - val_loss: 0.7131 - val_accuracy: 0.7457\n",
            "Epoch 64/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.5840 - accuracy: 0.7821 - val_loss: 0.7053 - val_accuracy: 0.7358\n",
            "Epoch 65/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.5952 - accuracy: 0.7787 - val_loss: 0.7193 - val_accuracy: 0.7418\n",
            "Epoch 66/80\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 0.5856 - accuracy: 0.7799 - val_loss: 0.7180 - val_accuracy: 0.7374\n",
            "Epoch 67/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.5958 - accuracy: 0.7836 - val_loss: 0.7384 - val_accuracy: 0.7315\n",
            "Epoch 68/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.5869 - accuracy: 0.7832 - val_loss: 0.7125 - val_accuracy: 0.7489\n",
            "Epoch 69/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.5930 - accuracy: 0.7808 - val_loss: 0.7571 - val_accuracy: 0.7311\n",
            "Epoch 70/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.5757 - accuracy: 0.7875 - val_loss: 0.7255 - val_accuracy: 0.7465\n",
            "Epoch 71/80\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 0.5874 - accuracy: 0.7822 - val_loss: 0.7218 - val_accuracy: 0.7398\n",
            "Epoch 72/80\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 0.5856 - accuracy: 0.7871 - val_loss: 0.7739 - val_accuracy: 0.7263\n",
            "Epoch 73/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.5860 - accuracy: 0.7846 - val_loss: 0.7281 - val_accuracy: 0.7481\n",
            "Epoch 74/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.5796 - accuracy: 0.7863 - val_loss: 0.7161 - val_accuracy: 0.7461\n",
            "Epoch 75/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.5830 - accuracy: 0.7835 - val_loss: 0.7390 - val_accuracy: 0.7366\n",
            "Epoch 76/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.5739 - accuracy: 0.7879 - val_loss: 0.7345 - val_accuracy: 0.7378\n",
            "Epoch 77/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.5798 - accuracy: 0.7877 - val_loss: 0.7085 - val_accuracy: 0.7438\n",
            "Epoch 78/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.5754 - accuracy: 0.7892 - val_loss: 0.7205 - val_accuracy: 0.7434\n",
            "Epoch 79/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.5739 - accuracy: 0.7876 - val_loss: 0.7361 - val_accuracy: 0.7323\n",
            "Epoch 80/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.5764 - accuracy: 0.7908 - val_loss: 0.7167 - val_accuracy: 0.7465\n",
            "Epoch 1/80\n",
            "703/703 [==============================] - 5s 5ms/step - loss: 1.5874 - accuracy: 0.2422 - val_loss: 1.4886 - val_accuracy: 0.3442\n",
            "Epoch 2/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.3966 - accuracy: 0.3945 - val_loss: 1.2924 - val_accuracy: 0.4368\n",
            "Epoch 3/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.3263 - accuracy: 0.4372 - val_loss: 1.2553 - val_accuracy: 0.4661\n",
            "Epoch 4/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.2890 - accuracy: 0.4594 - val_loss: 1.2139 - val_accuracy: 0.4899\n",
            "Epoch 5/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.2564 - accuracy: 0.4812 - val_loss: 1.2032 - val_accuracy: 0.5006\n",
            "Epoch 6/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.2326 - accuracy: 0.4952 - val_loss: 1.1705 - val_accuracy: 0.5042\n",
            "Epoch 7/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.2146 - accuracy: 0.5018 - val_loss: 1.1548 - val_accuracy: 0.5283\n",
            "Epoch 8/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.1958 - accuracy: 0.5131 - val_loss: 1.1230 - val_accuracy: 0.5299\n",
            "Epoch 9/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.1766 - accuracy: 0.5246 - val_loss: 1.1278 - val_accuracy: 0.5291\n",
            "Epoch 10/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.1618 - accuracy: 0.5316 - val_loss: 1.2428 - val_accuracy: 0.4907\n",
            "Epoch 11/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.1563 - accuracy: 0.5306 - val_loss: 1.0971 - val_accuracy: 0.5410\n",
            "Epoch 12/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.1426 - accuracy: 0.5399 - val_loss: 1.0980 - val_accuracy: 0.5406\n",
            "Epoch 13/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.1278 - accuracy: 0.5474 - val_loss: 1.0942 - val_accuracy: 0.5410\n",
            "Epoch 14/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.1161 - accuracy: 0.5536 - val_loss: 1.1172 - val_accuracy: 0.5303\n",
            "Epoch 15/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.1080 - accuracy: 0.5594 - val_loss: 1.0297 - val_accuracy: 0.5754\n",
            "Epoch 16/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.0975 - accuracy: 0.5657 - val_loss: 1.0710 - val_accuracy: 0.5485\n",
            "Epoch 17/80\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 1.0891 - accuracy: 0.5629 - val_loss: 1.0380 - val_accuracy: 0.5723\n",
            "Epoch 18/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.0786 - accuracy: 0.5748 - val_loss: 1.0712 - val_accuracy: 0.5568\n",
            "Epoch 19/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.0706 - accuracy: 0.5771 - val_loss: 1.0270 - val_accuracy: 0.5798\n",
            "Epoch 20/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.0697 - accuracy: 0.5791 - val_loss: 1.0514 - val_accuracy: 0.5695\n",
            "Epoch 21/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.0611 - accuracy: 0.5817 - val_loss: 0.9992 - val_accuracy: 0.5798\n",
            "Epoch 22/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.0578 - accuracy: 0.5813 - val_loss: 0.9802 - val_accuracy: 0.6000\n",
            "Epoch 23/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.0486 - accuracy: 0.5864 - val_loss: 1.0109 - val_accuracy: 0.5921\n",
            "Epoch 24/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.0422 - accuracy: 0.5917 - val_loss: 0.9654 - val_accuracy: 0.6032\n",
            "Epoch 25/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.0370 - accuracy: 0.5917 - val_loss: 0.9991 - val_accuracy: 0.5917\n",
            "Epoch 26/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.0359 - accuracy: 0.5977 - val_loss: 0.9795 - val_accuracy: 0.5956\n",
            "Epoch 27/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.0352 - accuracy: 0.5931 - val_loss: 1.0169 - val_accuracy: 0.5838\n",
            "Epoch 28/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.0271 - accuracy: 0.5976 - val_loss: 0.9953 - val_accuracy: 0.5972\n",
            "Epoch 29/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.0209 - accuracy: 0.5989 - val_loss: 1.0065 - val_accuracy: 0.5905\n",
            "Epoch 30/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.0186 - accuracy: 0.6003 - val_loss: 0.9944 - val_accuracy: 0.5937\n",
            "Epoch 31/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.0119 - accuracy: 0.6058 - val_loss: 0.9589 - val_accuracy: 0.6044\n",
            "Epoch 32/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.0082 - accuracy: 0.6085 - val_loss: 0.9758 - val_accuracy: 0.5992\n",
            "Epoch 33/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.0064 - accuracy: 0.6059 - val_loss: 0.9523 - val_accuracy: 0.6111\n",
            "Epoch 34/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.0044 - accuracy: 0.6030 - val_loss: 0.9621 - val_accuracy: 0.6051\n",
            "Epoch 35/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 1.0034 - accuracy: 0.6095 - val_loss: 1.0058 - val_accuracy: 0.5988\n",
            "Epoch 36/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9985 - accuracy: 0.6097 - val_loss: 0.9398 - val_accuracy: 0.6158\n",
            "Epoch 37/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9938 - accuracy: 0.6142 - val_loss: 0.9663 - val_accuracy: 0.6028\n",
            "Epoch 38/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9885 - accuracy: 0.6182 - val_loss: 0.9777 - val_accuracy: 0.5984\n",
            "Epoch 39/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9944 - accuracy: 0.6117 - val_loss: 0.9534 - val_accuracy: 0.6111\n",
            "Epoch 40/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9869 - accuracy: 0.6153 - val_loss: 0.9533 - val_accuracy: 0.6095\n",
            "Epoch 41/80\n",
            "703/703 [==============================] - 3s 4ms/step - loss: 0.9850 - accuracy: 0.6183 - val_loss: 0.9532 - val_accuracy: 0.6150\n",
            "Epoch 42/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9793 - accuracy: 0.6161 - val_loss: 0.9234 - val_accuracy: 0.6277\n",
            "Epoch 43/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9804 - accuracy: 0.6211 - val_loss: 0.9369 - val_accuracy: 0.6261\n",
            "Epoch 44/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9760 - accuracy: 0.6209 - val_loss: 0.9300 - val_accuracy: 0.6277\n",
            "Epoch 45/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9784 - accuracy: 0.6236 - val_loss: 0.9510 - val_accuracy: 0.6154\n",
            "Epoch 46/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9712 - accuracy: 0.6230 - val_loss: 0.9646 - val_accuracy: 0.6166\n",
            "Epoch 47/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9751 - accuracy: 0.6184 - val_loss: 0.9260 - val_accuracy: 0.6222\n",
            "Epoch 48/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9694 - accuracy: 0.6199 - val_loss: 0.9329 - val_accuracy: 0.6325\n",
            "Epoch 49/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9646 - accuracy: 0.6258 - val_loss: 0.9146 - val_accuracy: 0.6329\n",
            "Epoch 50/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9658 - accuracy: 0.6299 - val_loss: 0.9302 - val_accuracy: 0.6182\n",
            "Epoch 51/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9642 - accuracy: 0.6246 - val_loss: 0.9398 - val_accuracy: 0.6242\n",
            "Epoch 52/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9635 - accuracy: 0.6269 - val_loss: 0.9198 - val_accuracy: 0.6242\n",
            "Epoch 53/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9621 - accuracy: 0.6279 - val_loss: 0.9711 - val_accuracy: 0.6087\n",
            "Epoch 54/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9525 - accuracy: 0.6323 - val_loss: 0.9747 - val_accuracy: 0.6202\n",
            "Epoch 55/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9529 - accuracy: 0.6326 - val_loss: 0.9760 - val_accuracy: 0.6170\n",
            "Epoch 56/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9461 - accuracy: 0.6367 - val_loss: 0.9545 - val_accuracy: 0.6265\n",
            "Epoch 57/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9492 - accuracy: 0.6312 - val_loss: 0.9303 - val_accuracy: 0.6352\n",
            "Epoch 58/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9500 - accuracy: 0.6393 - val_loss: 0.9354 - val_accuracy: 0.6273\n",
            "Epoch 59/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9494 - accuracy: 0.6323 - val_loss: 0.9198 - val_accuracy: 0.6218\n",
            "Epoch 60/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9469 - accuracy: 0.6323 - val_loss: 0.9794 - val_accuracy: 0.6091\n",
            "Epoch 61/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9437 - accuracy: 0.6375 - val_loss: 0.9678 - val_accuracy: 0.6174\n",
            "Epoch 62/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9485 - accuracy: 0.6350 - val_loss: 0.9466 - val_accuracy: 0.6321\n",
            "Epoch 63/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9375 - accuracy: 0.6376 - val_loss: 0.9086 - val_accuracy: 0.6388\n",
            "Epoch 64/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9451 - accuracy: 0.6332 - val_loss: 0.9107 - val_accuracy: 0.6317\n",
            "Epoch 65/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9368 - accuracy: 0.6388 - val_loss: 0.9444 - val_accuracy: 0.6388\n",
            "Epoch 66/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9387 - accuracy: 0.6384 - val_loss: 0.9201 - val_accuracy: 0.6360\n",
            "Epoch 67/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9336 - accuracy: 0.6413 - val_loss: 0.9459 - val_accuracy: 0.6222\n",
            "Epoch 68/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9286 - accuracy: 0.6432 - val_loss: 0.9106 - val_accuracy: 0.6364\n",
            "Epoch 69/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9321 - accuracy: 0.6453 - val_loss: 0.9032 - val_accuracy: 0.6428\n",
            "Epoch 70/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9334 - accuracy: 0.6412 - val_loss: 0.9162 - val_accuracy: 0.6349\n",
            "Epoch 71/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9294 - accuracy: 0.6446 - val_loss: 0.9064 - val_accuracy: 0.6396\n",
            "Epoch 72/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9242 - accuracy: 0.6433 - val_loss: 0.9638 - val_accuracy: 0.6206\n",
            "Epoch 73/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9293 - accuracy: 0.6396 - val_loss: 0.8987 - val_accuracy: 0.6440\n",
            "Epoch 74/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9293 - accuracy: 0.6420 - val_loss: 0.9391 - val_accuracy: 0.6333\n",
            "Epoch 75/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9252 - accuracy: 0.6403 - val_loss: 0.9212 - val_accuracy: 0.6448\n",
            "Epoch 76/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9161 - accuracy: 0.6430 - val_loss: 0.8784 - val_accuracy: 0.6527\n",
            "Epoch 77/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9203 - accuracy: 0.6479 - val_loss: 0.9265 - val_accuracy: 0.6325\n",
            "Epoch 78/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9165 - accuracy: 0.6455 - val_loss: 0.9078 - val_accuracy: 0.6345\n",
            "Epoch 79/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9209 - accuracy: 0.6465 - val_loss: 0.8954 - val_accuracy: 0.6487\n",
            "Epoch 80/80\n",
            "703/703 [==============================] - 3s 5ms/step - loss: 0.9166 - accuracy: 0.6482 - val_loss: 0.9191 - val_accuracy: 0.6329\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.9191 - accuracy: 0.6329\n",
            "Validation Accuracy after pruning: 0.6328712701797485\n",
            "Sparsity: 0.8566229236692847\n",
            "Model Score: 0.7447470969245167\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPiJ_b1S4T-I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b56b2cdb-853a-4c60-e7c6-45b2e66f1181"
      },
      "source": [
        "# you need to save the model's weights, naming it 'my_model_weights.h5'\n",
        "pruned_model.save_weights(\"my_model_weights_3.h5\")\n",
        "\n",
        "# running this cell will immediately download a file called 'my_model_weights.h5'\n",
        "from google.colab import files\n",
        "files.download(\"my_model_weights_3.h5\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8ff46975-1766-4b30-af17-8c725ecbe14b\", \"my_model_weights_3.h5\", 2407040)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}