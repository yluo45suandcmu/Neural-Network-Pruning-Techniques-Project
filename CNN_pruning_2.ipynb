{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-eC-sb34T9w"
      },
      "source": [
        "## Accelerate Inference: Neural Network Pruning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L47XBZWm4T9x",
        "outputId": "65a19d5b-e929-432a-922c-5f1df35e5ccb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.14.0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import datasets, layers, models, regularizers\n",
        "from tensorflow.keras.layers import *\n",
        "\n",
        "print(tf.version.VERSION)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1FQTVeAuNiU",
        "outputId": "373acb7c-f405-4b2a-be1f-e70e23d3d46f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_images.pkl\n",
            "train_labels.pkl\n",
            "val_images.pkl\n",
            "val_labels.pkl\n"
          ]
        }
      ],
      "source": [
        "# untar\n",
        "!tar -xvzf /content/dataset.tar.gz\n",
        "\n",
        "# load train\n",
        "train_images = pickle.load(open('train_images.pkl', 'rb'))\n",
        "train_labels = pickle.load(open('train_labels.pkl', 'rb'))\n",
        "# load val\n",
        "val_images = pickle.load(open('val_images.pkl', 'rb'))\n",
        "val_labels = pickle.load(open('val_labels.pkl', 'rb'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KE9JuZDG4T94"
      },
      "outputs": [],
      "source": [
        "# Define the neural network architecture (don't change this)\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding='same', kernel_regularizer=regularizers.l2(1e-5), input_shape=(25,25,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(1e-5)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(64, (3, 3), padding='same', kernel_regularizer=regularizers.l2(1e-5)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(1e-5)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(5))\n",
        "model.add(Activation('softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTzcSoYl4T97",
        "outputId": "b9457185-6fdb-442d-ea10-58638e962e72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 25, 25, 32)        896       \n",
            "                                                                 \n",
            " activation (Activation)     (None, 25, 25, 32)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 23, 23, 32)        9248      \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 23, 23, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 11, 11, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 11, 11, 32)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 11, 11, 64)        18496     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 11, 11, 64)        0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 9, 9, 64)          36928     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 9, 9, 64)          0         \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 4, 4, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 4, 4, 64)          0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               524800    \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 512)               0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 2565      \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 5)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 592933 (2.26 MB)\n",
            "Trainable params: 592933 (2.26 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9Nk_MAPqZPt",
        "outputId": "74e8a317-8ae3-489f-f288-1edd396293d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "703/703 [==============================] - 22s 29ms/step - loss: 1.5090 - accuracy: 0.3116 - val_loss: 1.3498 - val_accuracy: 0.4186\n",
            "Epoch 2/50\n",
            "703/703 [==============================] - 20s 28ms/step - loss: 1.3410 - accuracy: 0.4224 - val_loss: 1.2659 - val_accuracy: 0.4646\n",
            "Epoch 3/50\n",
            "703/703 [==============================] - 21s 30ms/step - loss: 1.2719 - accuracy: 0.4659 - val_loss: 1.2218 - val_accuracy: 0.4812\n",
            "Epoch 4/50\n",
            "703/703 [==============================] - 20s 28ms/step - loss: 1.2328 - accuracy: 0.4862 - val_loss: 1.1902 - val_accuracy: 0.5069\n",
            "Epoch 5/50\n",
            "703/703 [==============================] - 20s 28ms/step - loss: 1.1988 - accuracy: 0.5058 - val_loss: 1.1500 - val_accuracy: 0.5267\n",
            "Epoch 6/50\n",
            "703/703 [==============================] - 20s 28ms/step - loss: 1.1622 - accuracy: 0.5232 - val_loss: 1.1317 - val_accuracy: 0.5394\n",
            "Epoch 7/50\n",
            "703/703 [==============================] - 20s 28ms/step - loss: 1.1306 - accuracy: 0.5402 - val_loss: 1.0923 - val_accuracy: 0.5517\n",
            "Epoch 8/50\n",
            "703/703 [==============================] - 19s 28ms/step - loss: 1.0997 - accuracy: 0.5567 - val_loss: 1.0530 - val_accuracy: 0.5727\n",
            "Epoch 9/50\n",
            "703/703 [==============================] - 20s 28ms/step - loss: 1.0735 - accuracy: 0.5697 - val_loss: 1.0622 - val_accuracy: 0.5651\n",
            "Epoch 10/50\n",
            "703/703 [==============================] - 20s 28ms/step - loss: 1.0524 - accuracy: 0.5794 - val_loss: 0.9948 - val_accuracy: 0.6028\n",
            "Epoch 11/50\n",
            "703/703 [==============================] - 20s 28ms/step - loss: 1.0326 - accuracy: 0.5881 - val_loss: 0.9873 - val_accuracy: 0.6012\n",
            "Epoch 12/50\n",
            "703/703 [==============================] - 20s 28ms/step - loss: 1.0201 - accuracy: 0.5961 - val_loss: 0.9616 - val_accuracy: 0.6051\n",
            "Epoch 13/50\n",
            "703/703 [==============================] - 19s 28ms/step - loss: 0.9990 - accuracy: 0.6055 - val_loss: 0.9602 - val_accuracy: 0.6028\n",
            "Epoch 14/50\n",
            "703/703 [==============================] - 20s 28ms/step - loss: 0.9826 - accuracy: 0.6139 - val_loss: 0.9695 - val_accuracy: 0.6071\n",
            "Epoch 15/50\n",
            "703/703 [==============================] - 19s 28ms/step - loss: 0.9647 - accuracy: 0.6217 - val_loss: 0.9263 - val_accuracy: 0.6265\n",
            "Epoch 16/50\n",
            "703/703 [==============================] - 21s 30ms/step - loss: 0.9585 - accuracy: 0.6255 - val_loss: 0.9494 - val_accuracy: 0.6186\n",
            "Epoch 17/50\n",
            "703/703 [==============================] - 20s 28ms/step - loss: 0.9447 - accuracy: 0.6304 - val_loss: 0.9221 - val_accuracy: 0.6289\n",
            "Epoch 18/50\n",
            "703/703 [==============================] - 20s 28ms/step - loss: 0.9271 - accuracy: 0.6328 - val_loss: 0.8973 - val_accuracy: 0.6416\n",
            "Epoch 19/50\n",
            "703/703 [==============================] - 21s 29ms/step - loss: 0.9207 - accuracy: 0.6436 - val_loss: 0.8867 - val_accuracy: 0.6388\n",
            "Epoch 20/50\n",
            "703/703 [==============================] - 20s 28ms/step - loss: 0.9030 - accuracy: 0.6497 - val_loss: 0.9052 - val_accuracy: 0.6281\n",
            "Epoch 21/50\n",
            "703/703 [==============================] - 20s 28ms/step - loss: 0.8937 - accuracy: 0.6533 - val_loss: 0.8608 - val_accuracy: 0.6598\n",
            "Epoch 22/50\n",
            "703/703 [==============================] - 20s 28ms/step - loss: 0.8821 - accuracy: 0.6568 - val_loss: 0.9073 - val_accuracy: 0.6293\n",
            "Epoch 23/50\n",
            "703/703 [==============================] - 20s 28ms/step - loss: 0.8709 - accuracy: 0.6626 - val_loss: 0.8558 - val_accuracy: 0.6574\n",
            "Epoch 24/50\n",
            "703/703 [==============================] - 19s 27ms/step - loss: 0.8612 - accuracy: 0.6666 - val_loss: 0.8390 - val_accuracy: 0.6642\n",
            "Epoch 25/50\n",
            "703/703 [==============================] - 19s 28ms/step - loss: 0.8505 - accuracy: 0.6694 - val_loss: 0.8312 - val_accuracy: 0.6709\n",
            "Epoch 26/50\n",
            "703/703 [==============================] - 19s 28ms/step - loss: 0.8374 - accuracy: 0.6818 - val_loss: 0.8531 - val_accuracy: 0.6602\n",
            "Epoch 27/50\n",
            "703/703 [==============================] - 19s 27ms/step - loss: 0.8268 - accuracy: 0.6816 - val_loss: 0.8290 - val_accuracy: 0.6796\n",
            "Epoch 28/50\n",
            "703/703 [==============================] - 20s 28ms/step - loss: 0.8078 - accuracy: 0.6890 - val_loss: 0.8180 - val_accuracy: 0.6832\n",
            "Epoch 29/50\n",
            "703/703 [==============================] - 19s 27ms/step - loss: 0.8090 - accuracy: 0.6904 - val_loss: 0.8328 - val_accuracy: 0.6602\n",
            "Epoch 30/50\n",
            "703/703 [==============================] - 20s 28ms/step - loss: 0.7957 - accuracy: 0.6970 - val_loss: 0.8156 - val_accuracy: 0.6820\n",
            "Epoch 31/50\n",
            "703/703 [==============================] - 19s 27ms/step - loss: 0.7839 - accuracy: 0.6986 - val_loss: 0.8098 - val_accuracy: 0.6808\n",
            "Epoch 32/50\n",
            "703/703 [==============================] - 19s 28ms/step - loss: 0.7740 - accuracy: 0.7030 - val_loss: 0.7870 - val_accuracy: 0.6911\n",
            "Epoch 33/50\n",
            "703/703 [==============================] - 19s 28ms/step - loss: 0.7639 - accuracy: 0.7069 - val_loss: 0.7828 - val_accuracy: 0.6895\n",
            "Epoch 34/50\n",
            "703/703 [==============================] - 19s 28ms/step - loss: 0.7570 - accuracy: 0.7127 - val_loss: 0.8081 - val_accuracy: 0.6800\n",
            "Epoch 35/50\n",
            "703/703 [==============================] - 20s 28ms/step - loss: 0.7476 - accuracy: 0.7152 - val_loss: 0.7695 - val_accuracy: 0.7030\n",
            "Epoch 36/50\n",
            "703/703 [==============================] - 19s 28ms/step - loss: 0.7427 - accuracy: 0.7181 - val_loss: 0.7693 - val_accuracy: 0.6974\n",
            "Epoch 37/50\n",
            "703/703 [==============================] - 19s 28ms/step - loss: 0.7308 - accuracy: 0.7214 - val_loss: 0.7745 - val_accuracy: 0.6982\n",
            "Epoch 38/50\n",
            "703/703 [==============================] - 19s 28ms/step - loss: 0.7249 - accuracy: 0.7234 - val_loss: 0.7644 - val_accuracy: 0.7042\n",
            "Epoch 39/50\n",
            "703/703 [==============================] - 20s 28ms/step - loss: 0.7144 - accuracy: 0.7293 - val_loss: 0.7523 - val_accuracy: 0.7034\n",
            "Epoch 40/50\n",
            "703/703 [==============================] - 19s 27ms/step - loss: 0.7072 - accuracy: 0.7346 - val_loss: 0.7419 - val_accuracy: 0.7129\n",
            "Epoch 41/50\n",
            "703/703 [==============================] - 19s 27ms/step - loss: 0.6993 - accuracy: 0.7370 - val_loss: 0.7498 - val_accuracy: 0.7156\n",
            "Epoch 42/50\n",
            "703/703 [==============================] - 20s 28ms/step - loss: 0.6963 - accuracy: 0.7388 - val_loss: 0.7844 - val_accuracy: 0.7006\n",
            "Epoch 43/50\n",
            "703/703 [==============================] - 19s 27ms/step - loss: 0.6782 - accuracy: 0.7459 - val_loss: 0.7348 - val_accuracy: 0.7160\n",
            "Epoch 44/50\n",
            "703/703 [==============================] - 20s 28ms/step - loss: 0.6738 - accuracy: 0.7455 - val_loss: 0.7678 - val_accuracy: 0.7093\n",
            "Epoch 45/50\n",
            "703/703 [==============================] - 19s 27ms/step - loss: 0.6670 - accuracy: 0.7486 - val_loss: 0.7258 - val_accuracy: 0.7240\n",
            "Epoch 46/50\n",
            "703/703 [==============================] - 19s 27ms/step - loss: 0.6648 - accuracy: 0.7496 - val_loss: 0.7193 - val_accuracy: 0.7267\n",
            "Epoch 47/50\n",
            "703/703 [==============================] - 20s 28ms/step - loss: 0.6524 - accuracy: 0.7543 - val_loss: 0.7550 - val_accuracy: 0.7093\n",
            "Epoch 48/50\n",
            "703/703 [==============================] - 19s 28ms/step - loss: 0.6444 - accuracy: 0.7584 - val_loss: 0.7413 - val_accuracy: 0.7125\n",
            "Epoch 49/50\n",
            "703/703 [==============================] - 20s 28ms/step - loss: 0.6380 - accuracy: 0.7615 - val_loss: 0.7246 - val_accuracy: 0.7196\n",
            "Epoch 50/50\n",
            "703/703 [==============================] - 20s 28ms/step - loss: 0.6328 - accuracy: 0.7617 - val_loss: 0.7389 - val_accuracy: 0.7236\n"
          ]
        }
      ],
      "source": [
        "# you can use the default hyper-parameters for training,\n",
        "# val accuracy ~72% after 50 epochs\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001, weight_decay=1e-6),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "              metrics=['accuracy'])\n",
        "tf.keras.backend.set_learning_phase(1)\n",
        "history = model.fit(train_images, train_labels, batch_size=32, epochs=50,\n",
        "                    validation_data=(val_images, val_labels)) # train for 50 epochs, with batch size 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOhpP7M24T9_",
        "outputId": "1fa41785-2c0f-494d-95a7-c9ce53c4ce18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 0s 23ms/step - loss: 0.7389 - accuracy: 0.7236\n"
          ]
        }
      ],
      "source": [
        "results = model.evaluate(val_images, val_labels, batch_size=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3QHMcTDkyj9",
        "outputId": "e9e0d970-7c82-4eef-923c-2ffb94e61c7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 0s 3ms/step - loss: 0.7437 - accuracy: 0.7129\n",
            "Validation Accuracy: 0.7128713130950928\n",
            "Sparsity: 0.0\n",
            "Model Score: 0\n"
          ]
        }
      ],
      "source": [
        "weights = model.get_weights()\n",
        "model.set_weights(weights)\n",
        "\n",
        "# Evaluate the pruned model\n",
        "val_loss, val_accuracy = model.evaluate(val_images, val_labels, batch_size=128)\n",
        "print(f\"Validation Accuracy: {val_accuracy}\")\n",
        "\n",
        "# Calculate the total number of weights\n",
        "total_weights = np.sum([np.prod(w.shape) for w in weights])\n",
        "\n",
        "# Calculate the number of zero weights (sparsity)\n",
        "num_zero_weights = np.sum([np.count_nonzero(w == 0) for w in weights])\n",
        "sparsity = num_zero_weights / total_weights\n",
        "print(f\"Sparsity: {sparsity}\")\n",
        "\n",
        "# Calculate the score based on the provided formula\n",
        "if val_accuracy > 0.6 and sparsity > 0:\n",
        "    score = (val_accuracy + sparsity) / 2\n",
        "else:\n",
        "    score = 0\n",
        "\n",
        "print(f\"Model Score: {score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6oTLGPpNnEBY"
      },
      "outputs": [],
      "source": [
        "\n",
        "# # you need to save the model's weights, naming it 'my_model_weights.h5'\n",
        "# model.save_weights(\"my_model_weights.h5\")\n",
        "\n",
        "# # running this cell will immediately download a file called 'my_model_weights.h5'\n",
        "# from google.colab import files\n",
        "# files.download(\"my_model_weights.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nomnt8xhrswU"
      },
      "source": [
        "# Intuitive Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ot8SRI3bn3yA"
      },
      "outputs": [],
      "source": [
        "# def prune_model(model, pruning_threshold):\n",
        "#     pruned_model = models.clone_model(model)\n",
        "#     pruned_model.set_weights(model.get_weights())  # Copy the weights from the original model\n",
        "\n",
        "#     for layer in pruned_model.layers:\n",
        "#         if isinstance(layer, layers.Conv2D) or isinstance(layer, layers.Dense):\n",
        "#             weights = layer.get_weights()\n",
        "#             pruned_weights = np.where(np.abs(weights[0]) < pruning_threshold, 0.0, weights[0])\n",
        "#             layer.set_weights([pruned_weights, weights[1]])\n",
        "\n",
        "#     return pruned_model\n",
        "\n",
        "# # Specify the pruning threshold\n",
        "# pruning_threshold = 0.015\n",
        "\n",
        "# # Apply pruning to the model\n",
        "# pruned_model = prune_model(model, pruning_threshold)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjEammoloyym"
      },
      "outputs": [],
      "source": [
        "# pruned_model.compile(\n",
        "#     optimizer=keras.optimizers.Adam(learning_rate=0.0001, weight_decay=1e-6),\n",
        "#     loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "#     metrics=['accuracy']\n",
        "# )\n",
        "\n",
        "# val_loss, val_accuracy = pruned_model.evaluate(val_images, val_labels, batch_size=128)\n",
        "# print(f\"Validation Accuracy: {val_accuracy}\")\n",
        "\n",
        "\n",
        "# total_weights = 0\n",
        "# zero_weights = 0\n",
        "# for layer in pruned_model.layers:\n",
        "#     if isinstance(layer, tf.keras.layers.Conv2D):\n",
        "#         weights = layer.get_weights()[0]\n",
        "#         total_weights += np.size(weights)\n",
        "#         zero_weights += np.count_nonzero(weights == 0)\n",
        "\n",
        "# sparsity = zero_weights / total_weights\n",
        "# print(f\"Sparsity: {sparsity}\")\n",
        "\n",
        "# # Calculate the model score\n",
        "# if val_accuracy > 0.6 and sparsity > 0:\n",
        "#     score = (val_accuracy + sparsity) / 2\n",
        "\n",
        "# else:\n",
        "#     score = 0\n",
        "\n",
        "# print(f\"Model Score: {score}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sy-pw0dtaxg"
      },
      "source": [
        "# Channel Pruning"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\text{argmin}_{\\beta, W} \\left( \\frac{1}{2N} \\left\\| Y - \\sum_{i=1}^{c} \\beta_i X_i W_i^T \\right\\|_F^2 + \\lambda \\left\\| \\beta \\right\\|_1 \\right)$  \n",
        "$\\text{subject to } \\| \\beta \\|_0 \\leq c', \\quad \\forall i \\quad \\| W_i \\|_F = 1$\n"
      ],
      "metadata": {
        "id": "sl3ulbNmSBNx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$X_i$: N$*$khkw matrix sliced from ith channel of input X, i = 1...c  \n",
        "$W_i$: n$*$khkw filter weights sliced from ith channel of W.\n",
        " n: number of output channels  \n",
        "$\\beta_i$: scalar mask to ith channel. If $\\beta_i = 0$, $X_i$ and $W_i$ will be removed.  \n",
        "$Y$: N$*$n output matrix.\n"
      ],
      "metadata": {
        "id": "hyrYLz0mMsWs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Channel Selction: Fix W and solve $\\beta$"
      ],
      "metadata": {
        "id": "gBZC23uKTbeA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_intermediate_model(layer_index):\n",
        "    # Create a model that outputs the activation of a specific layer\n",
        "    intermediate_model = tf.keras.Model(inputs=model.input,\n",
        "                                        outputs=model.layers[layer_index].output)\n",
        "    return intermediate_model\n",
        "\n",
        "# Get the number of layers in your model\n",
        "num_layers = len(model.layers)\n",
        "\n",
        "# Initialize lists to store X, Y, and W for each layer\n",
        "X_list = []\n",
        "Y_list = []\n",
        "W_list = []\n",
        "\n",
        "\n",
        "# Iterate through layers to get X, Y, and W\n",
        "for layer_index in range(num_layers):\n",
        "    layer = model.layers[layer_index]\n",
        "\n",
        "    # Create the intermediate model for the current layer\n",
        "    intermediate_model = get_intermediate_model(layer_index)\n",
        "\n",
        " # Get X (inputs), Y (outputs), and W (weights) for the current layer\n",
        "    X = train_images\n",
        "    Y = intermediate_model.predict(X)\n",
        "    W = layer.get_weights()\n",
        "\n",
        "    X_list.append(X)\n",
        "    Y_list.append(Y)\n",
        "    W_list.append(W)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YfEyNSJs71j",
        "outputId": "0746f2f1-4e0a-4519-f75c-d24d009d1f64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "703/703 [==============================] - 2s 3ms/step\n",
            "703/703 [==============================] - 2s 3ms/step\n",
            "703/703 [==============================] - 4s 5ms/step\n",
            "703/703 [==============================] - 4s 5ms/step\n",
            "703/703 [==============================] - 4s 5ms/step\n",
            "703/703 [==============================] - 4s 5ms/step\n",
            "703/703 [==============================] - 5s 7ms/step\n",
            "703/703 [==============================] - 5s 6ms/step\n",
            "703/703 [==============================] - 6s 8ms/step\n",
            "703/703 [==============================] - 6s 8ms/step\n",
            "703/703 [==============================] - 6s 9ms/step\n",
            "703/703 [==============================] - 6s 8ms/step\n",
            "703/703 [==============================] - 6s 8ms/step\n",
            "703/703 [==============================] - 6s 9ms/step\n",
            "703/703 [==============================] - 6s 9ms/step\n",
            "703/703 [==============================] - 7s 9ms/step\n",
            "703/703 [==============================] - 7s 9ms/step\n",
            "703/703 [==============================] - 6s 8ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2dqCIQizNwKH"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "\n",
        "def channel_selection(X, Y, W, c_prime, sparsity, alpha):\n",
        "\n",
        "    kh = kw = W.shape[1]\n",
        "    c = X.shape[-1]\n",
        "\n",
        "    X = X[:, :kh, :kw, :] #sample from X\n",
        "\n",
        "    if X.shape[1] != Y.shape[1]:\n",
        "      Y = Y[:, 1, 1, :] #padding = same\n",
        "    else :\n",
        "      Y = Y[:, 0, 0, :]\n",
        "\n",
        "    Y = Y.reshape(-1, 1)  # Reshape Y to a column vector\n",
        "\n",
        "    y_channel_spread = []\n",
        "\n",
        "    for i in range(c):\n",
        "      X_channel_i = X[:, :, :, i].reshape(X.shape[0],kw*kw)\n",
        "      W_channel_i = W[:, :, i, :].reshape(W.shape[-1],kw*kw)\n",
        "      # Apply convolution with the filter weights W\n",
        "      y_channel_i = np.matmul(X_channel_i,np.transpose(W_channel_i)).reshape(-1,1)\n",
        "      y_channel_spread.append(y_channel_i)\n",
        "\n",
        "    y_channel_spread = np.concatenate(y_channel_spread, axis=1)  # Stack along axis 1\n",
        "\n",
        "    solver = Lasso(alpha=alpha, selection='random', max_iter=1000, random_state=0, fit_intercept=False)\n",
        "\n",
        "    # Find the alpha to acheive the desires sparsity\n",
        "    alpha_l, alpha_r = 0, alpha\n",
        "    num_pruned_try = 0\n",
        "    while num_pruned_try < c_prime:\n",
        "          alpha_r *= 2\n",
        "          solver.alpha = alpha_r\n",
        "          solver.fit(y_channel_spread,Y)\n",
        "          num_pruned_try = sum(solver.coef_ == 0)\n",
        "\n",
        "    num_pruned_max = int(c_prime)\n",
        "    while True:\n",
        "          alpha = (alpha_l + alpha_r) / 2\n",
        "          solver.alpha = alpha\n",
        "          solver.fit(y_channel_spread,Y)\n",
        "          num_pruned_try = sum(solver.coef_ == 0)\n",
        "\n",
        "          if num_pruned_try > num_pruned_max:\n",
        "              alpha_r = alpha\n",
        "          elif num_pruned_try < c_prime:\n",
        "              alpha_l = alpha\n",
        "          else:\n",
        "              break\n",
        "\n",
        "    indices_stayed = np.where(solver.coef_ != 0)[0].tolist()\n",
        "    indices_pruned = np.where(solver.coef_ == 0)[0].tolist()\n",
        "\n",
        "    return indices_stayed, indices_pruned\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import clone_model\n",
        "def prune_model_channels(model, sparsity,alpha,prune_rate):\n",
        "    # Get the layers of the model\n",
        "    pruned_model = clone_model(model)\n",
        "    pruned_model.set_weights(model.get_weights())\n",
        "\n",
        "    # Iterate through convolutional layers to perform channel pruning\n",
        "    for i, layer in enumerate(pruned_model.layers) :\n",
        "        if isinstance(layer, tf.keras.layers.Conv2D):\n",
        "            weights = layer.get_weights()\n",
        "\n",
        "            # # Get the weights of the current convolutional layer\n",
        "            if i == 0:\n",
        "              X = np.array(X_list[i])\n",
        "            else:\n",
        "              X = np.array(Y_list[i-1])\n",
        "            Y = np.array(Y_list[i])\n",
        "\n",
        "            W = np.array(W_list[i][0])\n",
        "\n",
        "            c_in = W.shape[-2]\n",
        "\n",
        "            c_prime = int(np.floor(X.shape[-1] * sparsity)) # number of channels to prune based on the desired sparsity\n",
        "            print('c_prime:', c_prime)\n",
        "\n",
        "            # Stage1: Perform channel selection\n",
        "            indices_stayed, indices_pruned = channel_selection(X, Y, W, c_prime, sparsity, alpha)\n",
        "\n",
        "            print('c_prime:', c_prime, '\\nindices_stayed:', indices_stayed, '\\nindices_pruned:', indices_pruned)\n",
        "\n",
        "            for channel_index in indices_pruned:\n",
        "              weights[0][:, :, channel_index,:] = 0\n",
        "            #   X[:,:,:,channel_index]=0\n",
        "\n",
        "\n",
        "            #Potential weight reconstruction\n",
        "            # if X.shape[1] != Y.shape[1]:\n",
        "            #    Y_prime = Y[:, 1, 1, :].reshape(X.shape[0],W.shape[-1])\n",
        "            # else :\n",
        "            #    Y_prime = Y[:, 0, 0, :].reshape(X.shape[0],W.shape[-1])\n",
        "            # X_prime = X[:,:W.shape[1], :W.shape[1], :].reshape(X.shape[0],X.shape[-1]*W.shape[1]*W.shape[1])\n",
        "\n",
        "            # W_new = np.linalg.lstsq(X_prime,Y_prime, rcond=None)[0].reshape((W.shape[0], W.shape[1], W.shape[2], W.shape[3]))\n",
        "\n",
        "            # for channel_index in indices_pruned:\n",
        "            #   W_new[:, :, channel_index,:] = 0\n",
        "\n",
        "            layer.set_weights([weights[0],weights[1]])\n",
        "\n",
        "\n",
        "        elif isinstance(layer, tf.keras.layers.Dense):\n",
        "            weights = layer.get_weights()\n",
        "            weight_matrix, bias_vector = weights[0], weights[1]\n",
        "            threshold = np.percentile(np.abs(weight_matrix), prune_rate * 100)\n",
        "            pruned_weight_matrix = np.where(np.abs(weight_matrix) < threshold, 0, weight_matrix)\n",
        "\n",
        "            # Set the pruned weights and biases back to the layer\n",
        "            layer.set_weights([pruned_weight_matrix, bias_vector])\n",
        "\n",
        "\n",
        "    pruned_model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001, weight_decay=1e-6),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "              metrics=['accuracy'])\n",
        "    val_loss, val_accuracy = pruned_model.evaluate(val_images, val_labels, batch_size=128)\n",
        "    print(f\"Validation Accuracy: {val_accuracy}\")\n",
        "    total_weights = 0\n",
        "    zero_weights=0\n",
        "    for layer in pruned_model.layers:\n",
        "      if isinstance(layer, (tf.keras.layers.Dense,tf.keras.layers.Conv2D)):\n",
        "        weights = layer.get_weights()[0]\n",
        "        total_weights += np.size(weights)\n",
        "        zero_weights += np.count_nonzero(weights == 0)\n",
        "\n",
        "    sparsity = zero_weights / total_weights\n",
        "    print(f\"zero_weights:{zero_weights}\")\n",
        "    print(f\"total_weights:{total_weights}\")\n",
        "    print(f\"Sparsity: {sparsity}\")\n",
        "\n",
        "\n",
        "    # Calculate the model score\n",
        "    if val_accuracy > 0.6 and sparsity > 0:\n",
        "        score = (val_accuracy + sparsity) / 2\n",
        "\n",
        "    else:\n",
        "        score = 0\n",
        "\n",
        "    final_weights = pruned_model.get_weights()\n",
        "\n",
        "    pruned_model.save_weights(\"final_weights.h5\")\n",
        "\n",
        "    print('score:',score)\n",
        "    return score, final_weights\n"
      ],
      "metadata": {
        "id": "Eex9WMqGDFIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score, finalweight,s, a = prune_model_channels(model, sparsity = 0.05,alpha = 0.1,prune_rate=0.6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynsb471ZDoYU",
        "outputId": "1137a148-f483-46aa-cda5-2ba262e19262"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "c_prime: 0\n",
            "c_prime: 0 \n",
            "indices_stayed: [0, 1, 2] \n",
            "indices_pruned: []\n",
            "c_prime: 1\n",
            "c_prime: 1 \n",
            "indices_stayed: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31] \n",
            "indices_pruned: [9]\n",
            "c_prime: 1\n",
            "c_prime: 1 \n",
            "indices_stayed: [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31] \n",
            "indices_pruned: [2]\n",
            "c_prime: 3\n",
            "c_prime: 3 \n",
            "indices_stayed: [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63] \n",
            "indices_pruned: [6, 23, 33]\n",
            "20/20 [==============================] - 1s 23ms/step - loss: 0.8868 - accuracy: 0.6582\n",
            "Validation Accuracy: 0.6582178473472595\n",
            "zero_weights:266016\n",
            "total_weights:592224\n",
            "Sparsity: 0.44918139082509323\n",
            "score: 0.5536996190861764\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s_list = []\n",
        "a_list = []\n",
        "for sparsity in [0.05,0.1,0.15,0.2]:\n",
        "  for prune_rate in [0.45,0.5,0.55,0.6]:\n",
        "    print(sparsity, prune_rate)\n",
        "    score, finalweight, s, a = prune_model_channels(model, sparsity = sparsity,alpha = 0.1,prune_rate=prune_rate)\n",
        "    s_list.append(s)\n",
        "    a_list.append(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yqm31fO2HfZs",
        "outputId": "7050b3d1-0a7b-4aeb-b12b-c685d86b5114"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.05 0.45\n",
            "c_prime: 0\n",
            "c_prime: 0 \n",
            "indices_stayed: [0, 1, 2] \n",
            "indices_pruned: []\n",
            "c_prime: 1\n",
            "c_prime: 1 \n",
            "indices_stayed: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31] \n",
            "indices_pruned: [9]\n",
            "c_prime: 1\n",
            "c_prime: 1 \n",
            "indices_stayed: [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31] \n",
            "indices_pruned: [2]\n",
            "c_prime: 3\n",
            "c_prime: 3 \n",
            "indices_stayed: [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63] \n",
            "indices_pruned: [6, 23, 33]\n",
            "20/20 [==============================] - 1s 21ms/step - loss: 0.8814 - accuracy: 0.6614\n",
            "Validation Accuracy: 0.6613861322402954\n",
            "zero_weights:239674\n",
            "total_weights:592224\n",
            "Sparsity: 0.4047015993948236\n",
            "score: 0.5330438658175595\n",
            "0.05 0.5\n",
            "c_prime: 0\n",
            "c_prime: 0 \n",
            "indices_stayed: [0, 1, 2] \n",
            "indices_pruned: []\n",
            "c_prime: 1\n",
            "c_prime: 1 \n",
            "indices_stayed: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31] \n",
            "indices_pruned: [9]\n",
            "c_prime: 1\n",
            "c_prime: 1 \n",
            "indices_stayed: [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31] \n",
            "indices_pruned: [2]\n",
            "c_prime: 3\n",
            "c_prime: 3 \n",
            "indices_stayed: [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63] \n",
            "indices_pruned: [6, 23, 33]\n",
            "20/20 [==============================] - 1s 21ms/step - loss: 0.8868 - accuracy: 0.6582\n",
            "Validation Accuracy: 0.6582178473472595\n",
            "zero_weights:266016\n",
            "total_weights:592224\n",
            "Sparsity: 0.44918139082509323\n",
            "score: 0.5536996190861764\n",
            "0.05 0.55\n",
            "c_prime: 0\n",
            "c_prime: 0 \n",
            "indices_stayed: [0, 1, 2] \n",
            "indices_pruned: []\n",
            "c_prime: 1\n",
            "c_prime: 1 \n",
            "indices_stayed: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31] \n",
            "indices_pruned: [9]\n",
            "c_prime: 1\n",
            "c_prime: 1 \n",
            "indices_stayed: [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31] \n",
            "indices_pruned: [2]\n",
            "c_prime: 3\n",
            "c_prime: 3 \n",
            "indices_stayed: [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63] \n",
            "indices_pruned: [6, 23, 33]\n",
            "20/20 [==============================] - 1s 22ms/step - loss: 0.8819 - accuracy: 0.6594\n",
            "Validation Accuracy: 0.6594059467315674\n",
            "zero_weights:292358\n",
            "total_weights:592224\n",
            "Sparsity: 0.4936611822553628\n",
            "score: 0.576533564493465\n",
            "0.05 0.6\n",
            "c_prime: 0\n",
            "c_prime: 0 \n",
            "indices_stayed: [0, 1, 2] \n",
            "indices_pruned: []\n",
            "c_prime: 1\n",
            "c_prime: 1 \n",
            "indices_stayed: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31] \n",
            "indices_pruned: [9]\n",
            "c_prime: 1\n",
            "c_prime: 1 \n",
            "indices_stayed: [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31] \n",
            "indices_pruned: [2]\n",
            "c_prime: 3\n",
            "c_prime: 3 \n",
            "indices_stayed: [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63] \n",
            "indices_pruned: [6, 23, 33]\n",
            "20/20 [==============================] - 1s 23ms/step - loss: 0.8860 - accuracy: 0.6586\n",
            "Validation Accuracy: 0.6586138606071472\n",
            "zero_weights:318701\n",
            "total_weights:592224\n",
            "Sparsity: 0.5381426622359108\n",
            "score: 0.598378261421529\n",
            "0.1 0.45\n",
            "c_prime: 0\n",
            "c_prime: 0 \n",
            "indices_stayed: [0, 1, 2] \n",
            "indices_pruned: []\n",
            "c_prime: 3\n",
            "c_prime: 3 \n",
            "indices_stayed: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 25, 26, 27, 28, 29, 30, 31] \n",
            "indices_pruned: [9, 21, 24]\n",
            "c_prime: 3\n",
            "c_prime: 3 \n",
            "indices_stayed: [0, 1, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31] \n",
            "indices_pruned: [2, 3, 4]\n",
            "c_prime: 6\n",
            "c_prime: 6 \n",
            "indices_stayed: [0, 1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63] \n",
            "indices_pruned: [6, 9, 18, 23, 33, 46]\n",
            "20/20 [==============================] - 1s 21ms/step - loss: 1.2236 - accuracy: 0.5533\n",
            "Validation Accuracy: 0.5532673001289368\n",
            "zero_weights:243130\n",
            "total_weights:592224\n",
            "Sparsity: 0.41053722915653534\n",
            "score: 0\n",
            "0.1 0.5\n",
            "c_prime: 0\n",
            "c_prime: 0 \n",
            "indices_stayed: [0, 1, 2] \n",
            "indices_pruned: []\n",
            "c_prime: 3\n",
            "c_prime: 3 \n",
            "indices_stayed: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 25, 26, 27, 28, 29, 30, 31] \n",
            "indices_pruned: [9, 21, 24]\n",
            "c_prime: 3\n",
            "c_prime: 3 \n",
            "indices_stayed: [0, 1, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31] \n",
            "indices_pruned: [2, 3, 4]\n",
            "c_prime: 6\n",
            "c_prime: 6 \n",
            "indices_stayed: [0, 1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63] \n",
            "indices_pruned: [6, 9, 18, 23, 33, 46]\n",
            "20/20 [==============================] - 1s 22ms/step - loss: 1.2196 - accuracy: 0.5453\n",
            "Validation Accuracy: 0.5453465580940247\n",
            "zero_weights:269472\n",
            "total_weights:592224\n",
            "Sparsity: 0.455017020586805\n",
            "score: 0\n",
            "0.1 0.55\n",
            "c_prime: 0\n",
            "c_prime: 0 \n",
            "indices_stayed: [0, 1, 2] \n",
            "indices_pruned: []\n",
            "c_prime: 3\n",
            "c_prime: 3 \n",
            "indices_stayed: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 25, 26, 27, 28, 29, 30, 31] \n",
            "indices_pruned: [9, 21, 24]\n",
            "c_prime: 3\n",
            "c_prime: 3 \n",
            "indices_stayed: [0, 1, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31] \n",
            "indices_pruned: [2, 3, 4]\n",
            "c_prime: 6\n",
            "c_prime: 6 \n",
            "indices_stayed: [0, 1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63] \n",
            "indices_pruned: [6, 9, 18, 23, 33, 46]\n",
            "20/20 [==============================] - 1s 21ms/step - loss: 1.1944 - accuracy: 0.5446\n",
            "Validation Accuracy: 0.5445544719696045\n",
            "zero_weights:295814\n",
            "total_weights:592224\n",
            "Sparsity: 0.49949681201707463\n",
            "score: 0\n",
            "0.1 0.6\n",
            "c_prime: 0\n",
            "c_prime: 0 \n",
            "indices_stayed: [0, 1, 2] \n",
            "indices_pruned: []\n",
            "c_prime: 3\n",
            "c_prime: 3 \n",
            "indices_stayed: [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 25, 26, 27, 28, 29, 30, 31] \n",
            "indices_pruned: [9, 21, 24]\n",
            "c_prime: 3\n",
            "c_prime: 3 \n",
            "indices_stayed: [0, 1, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31] \n",
            "indices_pruned: [2, 3, 4]\n",
            "c_prime: 6\n",
            "c_prime: 6 \n",
            "indices_stayed: [0, 1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63] \n",
            "indices_pruned: [6, 9, 18, 23, 33, 46]\n",
            "20/20 [==============================] - 1s 21ms/step - loss: 1.1582 - accuracy: 0.5505\n",
            "Validation Accuracy: 0.5504950284957886\n",
            "zero_weights:322157\n",
            "total_weights:592224\n",
            "Sparsity: 0.5439782919976225\n",
            "score: 0\n",
            "0.15 0.45\n",
            "c_prime: 0\n",
            "c_prime: 0 \n",
            "indices_stayed: [0, 1, 2] \n",
            "indices_pruned: []\n",
            "c_prime: 4\n",
            "c_prime: 4 \n",
            "indices_stayed: [1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 25, 26, 27, 28, 29, 30, 31] \n",
            "indices_pruned: [0, 9, 21, 24]\n",
            "c_prime: 4\n",
            "c_prime: 4 \n",
            "indices_stayed: [0, 1, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31] \n",
            "indices_pruned: [2, 3, 4, 17]\n",
            "c_prime: 9\n",
            "c_prime: 9 \n",
            "indices_stayed: [0, 1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 54, 55, 56, 58, 59, 60, 61, 62, 63] \n",
            "indices_pruned: [6, 9, 18, 23, 24, 33, 46, 53, 57]\n",
            "20/20 [==============================] - 1s 21ms/step - loss: 1.4098 - accuracy: 0.4887\n",
            "Validation Accuracy: 0.488712877035141\n",
            "zero_weights:245722\n",
            "total_weights:592224\n",
            "Sparsity: 0.4149139514778192\n",
            "score: 0\n",
            "0.15 0.5\n",
            "c_prime: 0\n",
            "c_prime: 0 \n",
            "indices_stayed: [0, 1, 2] \n",
            "indices_pruned: []\n",
            "c_prime: 4\n",
            "c_prime: 4 \n",
            "indices_stayed: [1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 25, 26, 27, 28, 29, 30, 31] \n",
            "indices_pruned: [0, 9, 21, 24]\n",
            "c_prime: 4\n",
            "c_prime: 4 \n",
            "indices_stayed: [0, 1, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31] \n",
            "indices_pruned: [2, 3, 4, 17]\n",
            "c_prime: 9\n",
            "c_prime: 9 \n",
            "indices_stayed: [0, 1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 54, 55, 56, 58, 59, 60, 61, 62, 63] \n",
            "indices_pruned: [6, 9, 18, 23, 24, 33, 46, 53, 57]\n",
            "20/20 [==============================] - 1s 24ms/step - loss: 1.3990 - accuracy: 0.4796\n",
            "Validation Accuracy: 0.47960394620895386\n",
            "zero_weights:272064\n",
            "total_weights:592224\n",
            "Sparsity: 0.4593937429080888\n",
            "score: 0\n",
            "0.15 0.55\n",
            "c_prime: 0\n",
            "c_prime: 0 \n",
            "indices_stayed: [0, 1, 2] \n",
            "indices_pruned: []\n",
            "c_prime: 4\n",
            "c_prime: 4 \n",
            "indices_stayed: [1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 25, 26, 27, 28, 29, 30, 31] \n",
            "indices_pruned: [0, 9, 21, 24]\n",
            "c_prime: 4\n",
            "c_prime: 4 \n",
            "indices_stayed: [0, 1, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31] \n",
            "indices_pruned: [2, 3, 4, 17]\n",
            "c_prime: 9\n",
            "c_prime: 9 \n",
            "indices_stayed: [0, 1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 54, 55, 56, 58, 59, 60, 61, 62, 63] \n",
            "indices_pruned: [6, 9, 18, 23, 24, 33, 46, 53, 57]\n",
            "20/20 [==============================] - 1s 23ms/step - loss: 1.3652 - accuracy: 0.4788\n",
            "Validation Accuracy: 0.4788118898868561\n",
            "zero_weights:298406\n",
            "total_weights:592224\n",
            "Sparsity: 0.5038735343383585\n",
            "score: 0\n",
            "0.15 0.6\n",
            "c_prime: 0\n",
            "c_prime: 0 \n",
            "indices_stayed: [0, 1, 2] \n",
            "indices_pruned: []\n",
            "c_prime: 4\n",
            "c_prime: 4 \n",
            "indices_stayed: [1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 25, 26, 27, 28, 29, 30, 31] \n",
            "indices_pruned: [0, 9, 21, 24]\n",
            "c_prime: 4\n",
            "c_prime: 4 \n",
            "indices_stayed: [0, 1, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31] \n",
            "indices_pruned: [2, 3, 4, 17]\n",
            "c_prime: 9\n",
            "c_prime: 9 \n",
            "indices_stayed: [0, 1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 54, 55, 56, 58, 59, 60, 61, 62, 63] \n",
            "indices_pruned: [6, 9, 18, 23, 24, 33, 46, 53, 57]\n",
            "20/20 [==============================] - 1s 21ms/step - loss: 1.3103 - accuracy: 0.4867\n",
            "Validation Accuracy: 0.4867326617240906\n",
            "zero_weights:324749\n",
            "total_weights:592224\n",
            "Sparsity: 0.5483550143189063\n",
            "score: 0\n",
            "0.2 0.45\n",
            "c_prime: 0\n",
            "c_prime: 0 \n",
            "indices_stayed: [0, 1, 2] \n",
            "indices_pruned: []\n",
            "c_prime: 6\n",
            "c_prime: 6 \n",
            "indices_stayed: [1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 23, 25, 26, 27, 28, 29, 30, 31] \n",
            "indices_pruned: [0, 6, 9, 21, 22, 24]\n",
            "c_prime: 6\n",
            "c_prime: 6 \n",
            "indices_stayed: [0, 1, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31] \n",
            "indices_pruned: [2, 3, 4, 17, 18, 25]\n",
            "c_prime: 12\n",
            "c_prime: 12 \n",
            "indices_stayed: [0, 1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 20, 21, 22, 25, 26, 27, 28, 29, 30, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 55, 56, 58, 59, 60, 61, 62, 63] \n",
            "indices_pruned: [6, 9, 18, 19, 23, 24, 31, 33, 46, 53, 54, 57]\n",
            "20/20 [==============================] - 1s 21ms/step - loss: 1.8314 - accuracy: 0.3857\n",
            "Validation Accuracy: 0.38574257493019104\n",
            "zero_weights:249178\n",
            "total_weights:592224\n",
            "Sparsity: 0.420749581239531\n",
            "score: 0\n",
            "0.2 0.5\n",
            "c_prime: 0\n",
            "c_prime: 0 \n",
            "indices_stayed: [0, 1, 2] \n",
            "indices_pruned: []\n",
            "c_prime: 6\n",
            "c_prime: 6 \n",
            "indices_stayed: [1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 23, 25, 26, 27, 28, 29, 30, 31] \n",
            "indices_pruned: [0, 6, 9, 21, 22, 24]\n",
            "c_prime: 6\n",
            "c_prime: 6 \n",
            "indices_stayed: [0, 1, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31] \n",
            "indices_pruned: [2, 3, 4, 17, 18, 25]\n",
            "c_prime: 12\n",
            "c_prime: 12 \n",
            "indices_stayed: [0, 1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 20, 21, 22, 25, 26, 27, 28, 29, 30, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 55, 56, 58, 59, 60, 61, 62, 63] \n",
            "indices_pruned: [6, 9, 18, 19, 23, 24, 31, 33, 46, 53, 54, 57]\n",
            "20/20 [==============================] - 1s 21ms/step - loss: 1.8035 - accuracy: 0.3782\n",
            "Validation Accuracy: 0.37821781635284424\n",
            "zero_weights:275520\n",
            "total_weights:592224\n",
            "Sparsity: 0.46522937266980063\n",
            "score: 0\n",
            "0.2 0.55\n",
            "c_prime: 0\n",
            "c_prime: 0 \n",
            "indices_stayed: [0, 1, 2] \n",
            "indices_pruned: []\n",
            "c_prime: 6\n",
            "c_prime: 6 \n",
            "indices_stayed: [1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 23, 25, 26, 27, 28, 29, 30, 31] \n",
            "indices_pruned: [0, 6, 9, 21, 22, 24]\n",
            "c_prime: 6\n",
            "c_prime: 6 \n",
            "indices_stayed: [0, 1, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31] \n",
            "indices_pruned: [2, 3, 4, 17, 18, 25]\n",
            "c_prime: 12\n",
            "c_prime: 12 \n",
            "indices_stayed: [0, 1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 20, 21, 22, 25, 26, 27, 28, 29, 30, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 55, 56, 58, 59, 60, 61, 62, 63] \n",
            "indices_pruned: [6, 9, 18, 19, 23, 24, 31, 33, 46, 53, 54, 57]\n",
            "20/20 [==============================] - 1s 22ms/step - loss: 1.7335 - accuracy: 0.3762\n",
            "Validation Accuracy: 0.3762376308441162\n",
            "zero_weights:301862\n",
            "total_weights:592224\n",
            "Sparsity: 0.5097091641000703\n",
            "score: 0\n",
            "0.2 0.6\n",
            "c_prime: 0\n",
            "c_prime: 0 \n",
            "indices_stayed: [0, 1, 2] \n",
            "indices_pruned: []\n",
            "c_prime: 6\n",
            "c_prime: 6 \n",
            "indices_stayed: [1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 23, 25, 26, 27, 28, 29, 30, 31] \n",
            "indices_pruned: [0, 6, 9, 21, 22, 24]\n",
            "c_prime: 6\n",
            "c_prime: 6 \n",
            "indices_stayed: [0, 1, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31] \n",
            "indices_pruned: [2, 3, 4, 17, 18, 25]\n",
            "c_prime: 12\n",
            "c_prime: 12 \n",
            "indices_stayed: [0, 1, 2, 3, 4, 5, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 20, 21, 22, 25, 26, 27, 28, 29, 30, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 55, 56, 58, 59, 60, 61, 62, 63] \n",
            "indices_pruned: [6, 9, 18, 19, 23, 24, 31, 33, 46, 53, 54, 57]\n",
            "20/20 [==============================] - 1s 22ms/step - loss: 1.6160 - accuracy: 0.3857\n",
            "Validation Accuracy: 0.38574257493019104\n",
            "zero_weights:328205\n",
            "total_weights:592224\n",
            "Sparsity: 0.5541906440806181\n",
            "score: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def c(numbers):\n",
        "    if len(numbers) == 0:\n",
        "        return 0  # Handle the case where the list is empty to avoid division by zero.\n",
        "\n",
        "    # Calculate the mean.\n",
        "    mean = sum(numbers) / len(numbers)\n",
        "    return mean\n",
        "\n",
        "\n",
        "plt.plot([0.05,0.1,0.15,0.2],[c(a_list[:4]),c(a_list[4:8]),c(a_list[8:12]),c(a_list[12:16])])\n",
        "plt.xlabel('sparisty: percentage of channels to prune in each layer')\n",
        "plt.ylabel('validation accuracy')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "OqVY6DL-QvCd",
        "outputId": "46c3e272-9c62-465f-ad00-cfbd846f1ce3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'validation accuracy')"
            ]
          },
          "metadata": {},
          "execution_count": 70
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Kernal wise adaptive pruning rate"
      ],
      "metadata": {
        "id": "hBHUd-TvM3V5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import clone_model\n",
        "def prune_model_channels(model, prune_rate):\n",
        "    pruned_model = clone_model(model)\n",
        "    pruned_model.set_weights(model.get_weights())\n",
        "\n",
        "    # Iterate through convolutional layers to perform channel pruning\n",
        "    for i, layer in enumerate(pruned_model.layers) :\n",
        "        if isinstance(layer, tf.keras.layers.Conv2D):\n",
        "            weights = layer.get_weights()[0]\n",
        "\n",
        "            for j in range(weights.shape[-2]):\n",
        "              for k in range(weights.shape[-1]):\n",
        "                  current_filter = weights[:, :, j, k]\n",
        "                  threshold = np.percentile(np.abs(current_filter), (100 - 95)*i)\n",
        "                # Set weights below the threshold to zero\n",
        "                  weights[:, :, j, k] *= (np.abs(weights[:, :, j, k]) >= threshold).astype(float)\n",
        "\n",
        "            layer.set_weights([weights, layer.get_weights()[1]])\n",
        "\n",
        "        elif isinstance(layer, tf.keras.layers.Dense) and i!=len(pruned_model.layers)-1:\n",
        "            weights = layer.get_weights()\n",
        "            weight_matrix, bias_vector = weights[0], weights[1]\n",
        "\n",
        "            threshold = np.percentile(np.abs(weight_matrix), prune_rate * 100)\n",
        "\n",
        "            # Prune weights below the threshold by setting them to 0\n",
        "            pruned_weight_matrix = np.where(np.abs(weight_matrix) < threshold, 0, weight_matrix)\n",
        "\n",
        "            print(np.count_nonzero(pruned_weight_matrix == 0))\n",
        "\n",
        "\n",
        "            # Set the pruned weights and biases back to the layer\n",
        "            layer.set_weights([pruned_weight_matrix, bias_vector])\n",
        "\n",
        "\n",
        "    pruned_model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.00015, weight_decay=1e-6),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "    val_loss, val_accuracy = pruned_model.evaluate(val_images, val_labels, batch_size=128)\n",
        "    print(f\"Validation Accuracy: {val_accuracy}\")\n",
        "    total_weights = 0\n",
        "    zero_weights=0\n",
        "    for layer in pruned_model.layers:\n",
        "      if isinstance(layer, (tf.keras.layers.Dense,tf.keras.layers.Conv2D)):\n",
        "        weights = layer.get_weights()[0]\n",
        "        total_weights += np.size(weights)\n",
        "        zero_weights += np.count_nonzero(weights == 0)\n",
        "        print(total_weights, zero_weights)\n",
        "\n",
        "    sparsity = zero_weights / total_weights\n",
        "    print(f\"zero_weights:{zero_weights}\")\n",
        "    print(f\"total_weights:{total_weights}\")\n",
        "    print(f\"Sparsity: {sparsity}\")\n",
        "\n",
        "\n",
        "    # Calculate the model score\n",
        "    if val_accuracy > 0.6 and sparsity > 0:\n",
        "        score = (val_accuracy + sparsity) / 2\n",
        "\n",
        "    else:\n",
        "        score = 0\n",
        "\n",
        "    final_weights = pruned_model.get_weights()\n",
        "\n",
        "    pruned_model.save_weights(\"final_weights.h5\")\n",
        "\n",
        "    print('score:',score)\n",
        "    return score, final_weights"
      ],
      "metadata": {
        "id": "hvtkWJQkAgJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score_, finalweight_ = prune_model_channels(model, prune_rate=0.85)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPd9VslwCBNy",
        "outputId": "888ec0ad-d0ea-49b6-94f5-b61b4d666a77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "445644\n",
            "2176\n",
            "20/20 [==============================] - 1s 27ms/step - loss: 1.2166 - accuracy: 0.6626\n",
            "Validation Accuracy: 0.6625742316246033\n",
            "864 0\n",
            "10080 1024\n",
            "28512 7168\n",
            "65376 23552\n",
            "589664 469196\n",
            "592224 471372\n",
            "zero_weights:471372\n",
            "total_weights:592224\n",
            "Sparsity: 0.795935321770141\n",
            "score: 0.7292547766973722\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DEBnK6SIdvCd"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}